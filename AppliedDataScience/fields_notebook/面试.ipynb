{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/AppliedDataScience')\n",
    "import asyncio\n",
    "from call_api import call_gemini, async_call_gemini\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "field_name = \"面试\"\n",
    "field_path = f\"/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/AppliedDataScience/fields_csv/{field_name}.csv\"\n",
    "field_df = pd.read_csv(field_path)\n",
    "\n",
    "field_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an assistant whose only task is to decide whether the graduate program below **requires any form of interview or video assessment** and to give a one-sentence justification.\n",
    "\n",
    "ℹ️  What counts as an “interview”\n",
    "• Live interviews (in-person or virtual) **and** asynchronous video tasks (e.g., Kira Talent, prerecorded video essays).  \n",
    "• If the program labels the interview/video as *optional*, *by invitation*, or *for shortlisted applicants*, you must still treat it as **interview required**.  \n",
    "• Return **No requirement** only when **no** interview or video component is mentioned on official *.edu* pages.\n",
    "\n",
    "────────────────────────────────────────────────────────\n",
    "How to verify  \n",
    "\n",
    "1. **Primary *.edu* sources only**  \n",
    "   • Check the Admissions and Program URLs below.  \n",
    "   • You may open other pages on the same *.edu* domain (e.g., “Application Requirements”, “FAQ”, “Video Essay”, “Interview Process”).  \n",
    "   ⛔  Ignore non-*.edu* sites, blogs, forums, or news articles.\n",
    "\n",
    "2. **Google search (one query)**  \n",
    "   \"{university} {department} {degree} {program} interview video site:.edu\"  \n",
    "   Review *.edu* results only.\n",
    "\n",
    "3. **Decision rules**  \n",
    "   • If any page mentions a live interview or recorded video component—mandatory, optional, or by invitation—output **interview required**, then add a brief reason (e.g., “Official FAQ notes a required video interview”).  \n",
    "   • If no reference appears on official *.edu* pages, output **No requirement**, then add a brief reason (e.g., “No interview mentioned on program or admissions pages”).  \n",
    "   • Never infer or invent.\n",
    "\n",
    "────────────────────────────────────────────────────────\n",
    "⚠️  Output format (exactly one line, lowercase classification first, then a period and one short explanation)\n",
    "\n",
    "interview required. Official site states <reason>  \n",
    "No requirement. No interview mentioned on official pages  \n",
    "\n",
    "────────────────────────────────────────────────────────\n",
    "Pages to consult first:  \n",
    "• Admissions URL: {admissions_url}  \n",
    "• Program URL:    {program_url}\n",
    "\n",
    "Does this program require an interview or video assessment?\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "# Async Gemini wrapper\n",
    "from call_api import async_call_gemini\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Concurrency guard – avoid hitting rate-limits\n",
    "# ---------------------------------------------------------------------------\n",
    "semaphore = asyncio.Semaphore(3)            # max concurrent rows\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Per-row worker\n",
    "# ---------------------------------------------------------------------------\n",
    "async def process_row(row, prompt_template, num_vote: int, model_name: str):\n",
    "    \"\"\"\n",
    "    1. Format the prompt for this row\n",
    "    2. Launch `num_vote` Gemini calls in parallel\n",
    "    3. Capture BOTH normal answers *and* every possible error case\n",
    "    4. Return a serialisable record\n",
    "    \"\"\"\n",
    "    async with semaphore:\n",
    "        row    = row.to_dict()\n",
    "        prompt = prompt_template.format(\n",
    "            university     = row[\"大学英文名称\"],\n",
    "            degree         = row[\"学位\"],\n",
    "            program        = row[\"专业英文名称\"],\n",
    "            department     = row[\"所属院系（英文）\"],\n",
    "            admissions_url = row[\"招生网址\"],\n",
    "            program_url    = row[\"专业网址\"],\n",
    "        )\n",
    "\n",
    "        record: dict = row.copy()\n",
    "        record[\"llm_reponses\"] = {}\n",
    "\n",
    "        # -------- launch Gemini calls in parallel --------------------\n",
    "        tasks = [\n",
    "            async_call_gemini(\n",
    "                prompt,\n",
    "                model_name=model_name,\n",
    "                use_search=True,\n",
    "                url_context=True\n",
    "            )\n",
    "            for _ in range(num_vote)\n",
    "        ]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "\n",
    "        # -------- post-process each response -------------------------\n",
    "        for i, response in enumerate(responses):\n",
    "            resp_key = f\"response {i+1}\"\n",
    "\n",
    "            # -- 1. Transport / server-side errors (string starting \"Error:\")\n",
    "            if isinstance(response, str) and response.startswith(\"Error:\"):\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": response                       # e.g. \"Error: 429 Rate limit …\"\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 2. Empty / malformed response objects\n",
    "            if not hasattr(response, \"candidates\") or not response.candidates:\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": \"No candidates returned\",\n",
    "                    \"raw_response\": str(response)\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 3. Extract main answer text\n",
    "            try:\n",
    "                text = response.candidates[0].content.parts[0].text\n",
    "            except Exception as e:\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": f\"Cannot parse text: {e}\",\n",
    "                    \"raw_response\": str(response)\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 4. Extract additional metadata (best-effort)\n",
    "            try:\n",
    "                url_context = str(response.candidates[0].url_context_metadata)\n",
    "            except Exception:\n",
    "                url_context = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_pages = (\n",
    "                    f\"Search Chunks: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.grounding_chunks}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_pages = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_queries = (\n",
    "                    f\"Search Query: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.web_search_queries}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_queries = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_support = (\n",
    "                    f\"Search Supports: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.groundingSupports}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_support = \"Not used\"\n",
    "\n",
    "            # -- 5. Store normal answer + metadata + raw object\n",
    "            record[\"llm_reponses\"][resp_key] = {\n",
    "                \"response_text\": text,\n",
    "                \"url_context\": url_context,\n",
    "                \"search_queries\": search_queries,\n",
    "                \"search_pages\": search_pages,\n",
    "                \"search_support\": search_support,\n",
    "                \"raw_response\": str(response)             # keep for deep-debugging\n",
    "            }\n",
    "\n",
    "        return record\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Batch orchestrator with tqdm progress bar\n",
    "# ---------------------------------------------------------------------------\n",
    "async def request_and_store_async(prompt_template,\n",
    "                                  field_df,\n",
    "                                  num_vote: int,\n",
    "                                  model_name: str,\n",
    "                                  start_from: int = 0,\n",
    "                                  end_at: int = -1):\n",
    "    \"\"\"\n",
    "    Runs `process_row` over the dataframe slice asynchronously,\n",
    "    shows a live tqdm bar, and dumps the results to JSON.\n",
    "    \"\"\"\n",
    "    df = field_df.copy()[start_from:end_at]\n",
    "\n",
    "    # Spawn tasks for every row in the slice\n",
    "    tasks = [\n",
    "        process_row(row, prompt_template, num_vote, model_name)\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # tqdm_asyncio.gather gives us progress updates as tasks complete\n",
    "    response_records = await tqdm_asyncio.gather(*tasks)\n",
    "\n",
    "    # Persist to disk ------------------------------------------------\n",
    "    output_dir = f\"../fields_records/{field_name}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = f\"{output_dir}/{field_name}_{model_name}_{start_from}_{end_at}_newnewp.json\"\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(response_records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return response_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [10:09<00:00,  5.03s/it]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Only needed in Jupyter\n",
    "\n",
    "num_vote = 3\n",
    "start_from = 0\n",
    "end_at = len(field_df)\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "response_records = asyncio.run(\n",
    "    request_and_store_async(prompt_template, field_df, num_vote, model_name, start_from=start_from, end_at=end_at)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/AppliedDataScience/fields_records/面试/面试_gemini-2.5-flash_0_121_newnewp.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成！结果已保存到: /Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/AppliedDataScience/fields_records/面试/面试需求_处理结果_newp.csv\n",
      "总共处理了 121 条记录\n",
      "PhD项目（跳过）: 30 条\n",
      "需要面试: 10 条\n",
      "不需要面试: 81 条\n",
      "无法确定: 30 条\n",
      "\n",
      "前5条结果预览:\n",
      "                                  大学英文名称  \\\n",
      "0  Massachusetts Institute of Technology   \n",
      "1  Massachusetts Institute of Technology   \n",
      "2  Massachusetts Institute of Technology   \n",
      "3                     Harvard University   \n",
      "4                     Harvard University   \n",
      "\n",
      "                                              专业英文名称        学位   面试  \\\n",
      "0  Civil and Environmental Engineering：Data Scien...      Meng  不需要   \n",
      "1                     Social and Engineering Systems       PhD        \n",
      "2            Data, Economics, and Development Policy       MAS  不需要   \n",
      "3                            Master in Public Policy       MPP  不需要   \n",
      "4  Master in Public Administration in Internation...  MPP / ID  不需要   \n",
      "\n",
      "                     判定状态  \n",
      "0  投票结果-不需要(3票) vs 需要(0票)  \n",
      "1              PhD项目-默认跳过  \n",
      "2  投票结果-不需要(3票) vs 需要(0票)  \n",
      "3  投票结果-不需要(2票) vs 需要(0票)  \n",
      "4  投票结果-不需要(3票) vs 需要(0票)  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def extract_interview_requirements(json_file_path):\n",
    "    \"\"\"\n",
    "    从JSON文件中提取面试需求信息\n",
    "    \n",
    "    Args:\n",
    "        json_file_path: JSON文件路径\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: 处理后的数据\n",
    "    \"\"\"\n",
    "    \n",
    "    # 读取JSON文件\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for record in data:\n",
    "        # 提取基本信息\n",
    "        basic_info = {\n",
    "            '大学英文名称': record.get('大学英文名称', '').strip(),\n",
    "            '学位': record.get('学位', ''),\n",
    "            '专业英文名称': record.get('专业英文名称', ''),\n",
    "            '所属院系': record.get('所属院系', ''),\n",
    "            '所属院系（英文）': record.get('所属院系（英文）', ''),\n",
    "        }\n",
    "        \n",
    "        # 检查是否为PhD项目\n",
    "        phd = str(basic_info['学位'])\n",
    "        if \"p\" in phd.lower() and \"h\" in phd.lower() and \"d\" in phd.lower():\n",
    "            is_phd = True\n",
    "        else:\n",
    "            is_phd = False\n",
    "        \n",
    "        \n",
    "        if is_phd:\n",
    "            # PhD项目直接返回空\n",
    "            result = basic_info.copy()\n",
    "            result.update({\n",
    "                '面试': '',\n",
    "                '判定状态': 'PhD项目-默认跳过'\n",
    "            })\n",
    "            results.append(result)\n",
    "            continue\n",
    "        \n",
    "        # 处理Master项目的LLM回答\n",
    "        responses = record.get('llm_reponses', {})\n",
    "        valid_responses = []\n",
    "        \n",
    "        for response_key in ['response 1', 'response 2', 'response 3']:\n",
    "            if response_key in responses:\n",
    "                response_text = responses[response_key].get('response_text', '').strip()\n",
    "                \n",
    "                # 检查是否为无效回答\n",
    "                invalid_patterns = [\n",
    "                    r'^not found$',\n",
    "                    r'^the$',\n",
    "                    r'^error',\n",
    "                    r'^no data',\n",
    "                    r'^unable to',\n",
    "                    r'^could not',\n",
    "                    r'^\\w{1,3}$'  # 太短的回答（1-3个字符）\n",
    "                ]\n",
    "                \n",
    "                is_invalid = any(re.search(pattern, response_text.lower()) for pattern in invalid_patterns)\n",
    "                \n",
    "                if not is_invalid and response_text:\n",
    "                    # 判断回答内容\n",
    "                    response_lower = response_text.lower()\n",
    "                    \n",
    "                    if 'no requirement' in response_lower:\n",
    "                        valid_responses.append('不需要')\n",
    "                    elif any(keyword in response_lower for keyword in ['interview required', 'interview is required', 'requires interview']):\n",
    "                        valid_responses.append('需要')\n",
    "                    elif len(response_text) < 20 and 'no' in response_lower:\n",
    "                        # 短回答包含\"no\"的情况\n",
    "                        valid_responses.append('不需要')\n",
    "                    else:\n",
    "                        # 其他长回答，检查是否暗示不需要面试\n",
    "                        no_interview_indicators = [\n",
    "                            'do not mention',\n",
    "                            'does not mention', \n",
    "                            'not explicitly mention',\n",
    "                            'no explicit mention',\n",
    "                            'not listed',\n",
    "                            'not required',\n",
    "                            'not specified'\n",
    "                        ]\n",
    "                        \n",
    "                        if any(indicator in response_lower for indicator in no_interview_indicators):\n",
    "                            valid_responses.append('不需要')\n",
    "                        else:\n",
    "                            # 如果无法明确判断，暂时归类为无效\n",
    "                            pass\n",
    "        \n",
    "        # 投票决定结果\n",
    "        result = basic_info.copy()\n",
    "        \n",
    "        if not valid_responses:\n",
    "            result.update({\n",
    "                '面试': '',\n",
    "                '判定状态': '无有效回答'\n",
    "            })\n",
    "        else:\n",
    "            need_count = valid_responses.count('需要')\n",
    "            no_need_count = valid_responses.count('不需要')\n",
    "            \n",
    "            if need_count > no_need_count:\n",
    "                result.update({\n",
    "                    '面试': '需要',\n",
    "                    '判定状态': f'投票结果-需要({need_count}票) vs 不需要({no_need_count}票)'\n",
    "                })\n",
    "            elif no_need_count > need_count:\n",
    "                result.update({\n",
    "                    '面试': '不需要',\n",
    "                    '判定状态': f'投票结果-不需要({no_need_count}票) vs 需要({need_count}票)'\n",
    "                })\n",
    "            else:\n",
    "                result.update({\n",
    "                    '面试': '',\n",
    "                    '判定状态': f'投票平局-需要({need_count}票) vs 不需要({no_need_count}票)'\n",
    "                })\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def process_interview_json(json_file_path):\n",
    "    \"\"\"\n",
    "    处理面试JSON文件并保存结果\n",
    "    \"\"\"\n",
    "    \n",
    "    # 提取数据\n",
    "    df = extract_interview_requirements(json_file_path)\n",
    "    \n",
    "    # 生成输出文件名\n",
    "    output_path = os.path.join(os.path.dirname(json_file_path), \"面试需求_处理结果_newp.csv\")\n",
    "    \n",
    "    # 保存为CSV\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # 统计信息\n",
    "    total_records = len(df)\n",
    "    phd_records = len(df[df['判定状态'].str.contains('PhD项目')])\n",
    "    need_interview = len(df[df['面试'] == '需要'])\n",
    "    no_need_interview = len(df[df['面试'] == '不需要'])\n",
    "    unclear_records = len(df[df['面试'] == ''])\n",
    "    \n",
    "    print(f\"处理完成！结果已保存到: {output_path}\")\n",
    "    print(f\"总共处理了 {total_records} 条记录\")\n",
    "    print(f\"PhD项目（跳过）: {phd_records} 条\")\n",
    "    print(f\"需要面试: {need_interview} 条\")\n",
    "    print(f\"不需要面试: {no_need_interview} 条\")\n",
    "    print(f\"无法确定: {unclear_records} 条\")\n",
    "    \n",
    "    print(f\"\\n前5条结果预览:\")\n",
    "    print(df[['大学英文名称', '专业英文名称', '学位', '面试', '判定状态']].head())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 使用示例\n",
    "df = process_interview_json(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
