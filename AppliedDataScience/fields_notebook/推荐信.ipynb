{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 10)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/AppliedDataScience')\n",
    "import asyncio\n",
    "from call_api import call_gemini, async_call_gemini\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "field_name = \"推荐信\"\n",
    "field_path = f\"/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/AppliedDataScience/fields_csv/{field_name}.csv\"\n",
    "field_df = pd.read_csv(field_path)\n",
    "\n",
    "field_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an assistant that checks how many letters of recommendation are required for the following graduate program.\n",
    "\n",
    "1. Search the admissions and program webpages provided.  \n",
    "2. Use Google search to find more information.\n",
    "\n",
    "Answer instructions:\n",
    "Give your response in a short sentence. In most cases, the number of letters of recommendation is 2 or 3, so you should return \"2 letters of recommendation\" or \"3 letters of recommendation\", with nothing else.\n",
    "In rare cases, the program does not explicitly mention the number of letters of recommendation, you should return \"No explicit demands on letters of recommendation.\"\n",
    "\n",
    "Example response:\n",
    "\"3 letters of recommendation.\"\n",
    "\"2~3 letters of recommendation.\"\n",
    "\"3~4 letter of recommendation.\"\n",
    "\"Not mentioned.\" (rare cases)\n",
    "\n",
    "Use Google to search **\"{university} {degree} {department} {program} number of letters of recommendation\"** for more information.\n",
    "\n",
    "URLs you should check:\n",
    "• Admissions URL: {admissions_url}  \n",
    "• Program URL: {program_url}\n",
    "\n",
    "Here are your response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "# Async Gemini wrapper\n",
    "from call_api import async_call_gemini\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Concurrency guard – avoid hitting rate-limits\n",
    "# ---------------------------------------------------------------------------\n",
    "semaphore = asyncio.Semaphore(5)            # max concurrent rows\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Per-row worker\n",
    "# ---------------------------------------------------------------------------\n",
    "async def process_row(row, prompt_template, num_vote: int, model_name: str):\n",
    "    \"\"\"\n",
    "    1. Format the prompt for this row\n",
    "    2. Launch `num_vote` Gemini calls in parallel\n",
    "    3. Capture BOTH normal answers *and* every possible error case\n",
    "    4. Return a serialisable record\n",
    "    \"\"\"\n",
    "    async with semaphore:\n",
    "        row    = row.to_dict()\n",
    "        prompt = prompt_template.format(\n",
    "            university     = row[\"大学英文名称\"],\n",
    "            degree         = row[\"学位\"],\n",
    "            program        = row[\"专业英文名称\"],\n",
    "            department     = row[\"所属院系（英文）\"],\n",
    "            admissions_url = row[\"招生网址\"],\n",
    "            program_url    = row[\"专业网址\"],\n",
    "        )\n",
    "\n",
    "        record: dict = row.copy()\n",
    "        record[\"llm_reponses\"] = {}\n",
    "\n",
    "        # -------- launch Gemini calls in parallel --------------------\n",
    "        tasks = [\n",
    "            async_call_gemini(\n",
    "                prompt,\n",
    "                model_name=model_name,\n",
    "                use_search=True,\n",
    "                url_context=True\n",
    "            )\n",
    "            for _ in range(num_vote)\n",
    "        ]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "\n",
    "        # -------- post-process each response -------------------------\n",
    "        for i, response in enumerate(responses):\n",
    "            resp_key = f\"response {i+1}\"\n",
    "\n",
    "            # -- 1. Transport / server-side errors (string starting \"Error:\")\n",
    "            if isinstance(response, str) and response.startswith(\"Error:\"):\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": response                       # e.g. \"Error: 429 Rate limit …\"\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 2. Empty / malformed response objects\n",
    "            if not hasattr(response, \"candidates\") or not response.candidates:\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": \"No candidates returned\",\n",
    "                    \"raw_response\": str(response)\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 3. Extract main answer text\n",
    "            try:\n",
    "                text = response.candidates[0].content.parts[0].text\n",
    "            except Exception as e:\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": f\"Cannot parse text: {e}\",\n",
    "                    \"raw_response\": str(response)\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 4. Extract additional metadata (best-effort)\n",
    "            try:\n",
    "                url_context = str(response.candidates[0].url_context_metadata)\n",
    "            except Exception:\n",
    "                url_context = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_pages = (\n",
    "                    f\"Search Chunks: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.grounding_chunks}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_pages = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_queries = (\n",
    "                    f\"Search Query: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.web_search_queries}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_queries = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_support = (\n",
    "                    f\"Search Supports: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.groundingSupports}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_support = \"Not used\"\n",
    "\n",
    "            # -- 5. Store normal answer + metadata + raw object\n",
    "            record[\"llm_reponses\"][resp_key] = {\n",
    "                \"response_text\": text,\n",
    "                \"url_context\": url_context,\n",
    "                \"search_queries\": search_queries,\n",
    "                \"search_pages\": search_pages,\n",
    "                \"search_support\": search_support,\n",
    "                \"raw_response\": str(response)             # keep for deep-debugging\n",
    "            }\n",
    "\n",
    "        return record\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Batch orchestrator with tqdm progress bar\n",
    "# ---------------------------------------------------------------------------\n",
    "async def request_and_store_async(prompt_template,\n",
    "                                  field_df,\n",
    "                                  num_vote: int,\n",
    "                                  model_name: str,\n",
    "                                  start_from: int = 0,\n",
    "                                  end_at: int = -1):\n",
    "    \"\"\"\n",
    "    Runs `process_row` over the dataframe slice asynchronously,\n",
    "    shows a live tqdm bar, and dumps the results to JSON.\n",
    "    \"\"\"\n",
    "    df = field_df.copy()[start_from:end_at]\n",
    "\n",
    "    # Spawn tasks for every row in the slice\n",
    "    tasks = [\n",
    "        process_row(row, prompt_template, num_vote, model_name)\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # tqdm_asyncio.gather gives us progress updates as tasks complete\n",
    "    response_records = await tqdm_asyncio.gather(*tasks)\n",
    "\n",
    "    # Persist to disk ------------------------------------------------\n",
    "    output_dir = f\"../fields_records/{field_name}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = f\"{output_dir}/{field_name}_{model_name}_{start_from}_{end_at}.json\"\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(response_records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return response_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [10:08<00:00,  5.03s/it]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Only needed in Jupyter\n",
    "\n",
    "num_vote = 3\n",
    "start_from = 0\n",
    "end_at = len(field_df)\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "response_records = asyncio.run(\n",
    "    request_and_store_async(prompt_template, field_df, num_vote, model_name, start_from=start_from, end_at=end_at)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/AppliedDataScience/fields_records/推荐信/推荐信_gemini-2.5-flash_0_121.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成！结果已保存到: /Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/AppliedDataScience/fields_records/推荐信/推荐信_gemini-2.5-flash_0_121_processed.csv\n",
      "共处理 121 条记录\n",
      "\n",
      "推荐信需求分布:\n",
      "推荐信\n",
      "3 letters of recommendation    80\n",
      "2 letters of recommendation    24\n",
      "no explicit demand              8\n",
      "1 letters of recommendation     6\n",
      "0 letters of recommendation     1\n",
      "                                1\n",
      "4 letters of recommendation     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "判断状态分布:\n",
      "判断状态\n",
      "所有3个有效回答一致                      78\n",
      "所有2个有效回答一致                      25\n",
      "只有一个有效回答                         6\n",
      "所有3个有效回答都是no explicit demand     4\n",
      "no explicit demand回答占主导          3\n",
      "Majority vote: 3 (2/3)           1\n",
      "数字回答占主导，结果一致: 0                  1\n",
      "所有回答无效                           1\n",
      "数字回答占主导，结果一致: 3                  1\n",
      "平票情况，取更高数字: 3                    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "数据预览:\n",
      "                                  大学英文名称        学位  \\\n",
      "0  Massachusetts Institute of Technology      Meng   \n",
      "1  Massachusetts Institute of Technology       PhD   \n",
      "2  Massachusetts Institute of Technology       MAS   \n",
      "3                     Harvard University       MPP   \n",
      "4                     Harvard University  MPP / ID   \n",
      "5                     Harvard University       MPP   \n",
      "6                     Harvard University    MC/MPA   \n",
      "7                    Stanford University       PhD   \n",
      "8                    Stanford University        MS   \n",
      "9                    Stanford University       PhD   \n",
      "\n",
      "                                              专业英文名称  \\\n",
      "0  Civil and Environmental Engineering：Data Scien...   \n",
      "1                     Social and Engineering Systems   \n",
      "2            Data, Economics, and Development Policy   \n",
      "3                            Master in Public Policy   \n",
      "4  Master in Public Administration in Internation...   \n",
      "5                    Master in Public Administration   \n",
      "6         Mid-Career Master in Public Administration   \n",
      "7                            ‌Education Data Science   \n",
      "8                        Education Data Science (MS)   \n",
      "9                            Biomedical Data Science   \n",
      "\n",
      "                           推荐信        判断状态  \n",
      "0  3 letters of recommendation  所有3个有效回答一致  \n",
      "1  3 letters of recommendation  所有2个有效回答一致  \n",
      "2  2 letters of recommendation    只有一个有效回答  \n",
      "3  3 letters of recommendation  所有3个有效回答一致  \n",
      "4  3 letters of recommendation  所有3个有效回答一致  \n",
      "5  3 letters of recommendation  所有3个有效回答一致  \n",
      "6  3 letters of recommendation  所有3个有效回答一致  \n",
      "7  3 letters of recommendation  所有3个有效回答一致  \n",
      "8  3 letters of recommendation  所有3个有效回答一致  \n",
      "9  3 letters of recommendation  所有3个有效回答一致  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "def extract_recommendation_letters_info(json_file_path):\n",
    "    \"\"\"\n",
    "    从JSON文件中提取推荐信数量信息，使用majority vote判断\n",
    "    \n",
    "    Args:\n",
    "        json_file_path: JSON文件路径\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: 处理后的数据\n",
    "    \"\"\"\n",
    "    \n",
    "    # 读取JSON文件\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for record in data:\n",
    "        # 提取基本信息\n",
    "        basic_info = {\n",
    "            '大学英文名称': record.get('大学英文名称', '').strip(),\n",
    "            '学位': record.get('学位', ''),\n",
    "            '专业英文名称': record.get('专业英文名称', ''),\n",
    "            '所属院系': record.get('所属院系', ''),\n",
    "            '招生网址': record.get('招生网址', ''),\n",
    "            '专业网址': record.get('专业网址', ''),\n",
    "        }\n",
    "        \n",
    "        # 获取三个LLM responses\n",
    "        llm_responses = record.get('llm_reponses', {})\n",
    "        response_1 = llm_responses.get('response 1', {}).get('response_text', '').strip()\n",
    "        response_2 = llm_responses.get('response 2', {}).get('response_text', '').strip()\n",
    "        response_3 = llm_responses.get('response 3', {}).get('response_text', '').strip()\n",
    "        \n",
    "        # 数字映射字典\n",
    "        number_mapping = {\n",
    "            'zero': 0, 'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5,\n",
    "            '0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5\n",
    "        }\n",
    "        \n",
    "        def classify_response(response_text):\n",
    "            \"\"\"\n",
    "            分类单个回答\n",
    "            返回: 推荐信数量(int) 或 'no_explicit_demand' 或 'invalid'\n",
    "            \"\"\"\n",
    "            if not response_text or len(response_text.strip()) == 0:\n",
    "                return 'invalid'\n",
    "            \n",
    "            response_lower = response_text.lower()\n",
    "            \n",
    "            # 检查无效回答\n",
    "            invalid_patterns = [\n",
    "                r'^not found$',\n",
    "                r'^error',\n",
    "                r'^no data',\n",
    "                r'^unable to',\n",
    "                r'^cannot find',\n",
    "                r'^the\\s+.{50,}',  # 以\"The\"开头的长篇回答\n",
    "                r'incomplete',\n",
    "                r'insufficient'\n",
    "            ]\n",
    "            \n",
    "            for pattern in invalid_patterns:\n",
    "                if re.search(pattern, response_lower, re.IGNORECASE):\n",
    "                    return 'invalid'\n",
    "            \n",
    "            # 检查\"no explicit demand\"类型的回答\n",
    "            no_demand_patterns = [\n",
    "                r'no explicit demands?\\s+on\\s+letters?\\s+of\\s+recommendation',\n",
    "                r'not mentioned',\n",
    "                r'no\\s+specific\\s+requirement',\n",
    "                r'no\\s+requirement',\n",
    "                r'no\\s+explicit\\s+requirement',\n",
    "                r'not\\s+specified',\n",
    "                r'not\\s+stated',\n",
    "                r'no\\s+information',\n",
    "                r'does\\s+not\\s+mention'\n",
    "            ]\n",
    "            \n",
    "            for pattern in no_demand_patterns:\n",
    "                if re.search(pattern, response_lower, re.IGNORECASE):\n",
    "                    return 'no_explicit_demand'\n",
    "            \n",
    "            # 提取数字\n",
    "            # 匹配模式：X letters of recommendation, X letter of recommendation等\n",
    "            number_patterns = [\n",
    "                r'(\\d+)\\s+letters?\\s+of\\s+recommendation',\n",
    "                r'(\\w+)\\s+letters?\\s+of\\s+recommendation',\n",
    "                r'requires?\\s+(\\d+)\\s+letters?',\n",
    "                r'requires?\\s+(\\w+)\\s+letters?',\n",
    "                r'(\\d+)\\s+recommendation\\s+letters?',\n",
    "                r'(\\w+)\\s+recommendation\\s+letters?'\n",
    "            ]\n",
    "            \n",
    "            extracted_numbers = []\n",
    "            \n",
    "            for pattern in number_patterns:\n",
    "                matches = re.findall(pattern, response_lower, re.IGNORECASE)\n",
    "                for match in matches:\n",
    "                    if match.lower() in number_mapping:\n",
    "                        extracted_numbers.append(number_mapping[match.lower()])\n",
    "                    elif match.isdigit():\n",
    "                        num = int(match)\n",
    "                        if 0 <= num <= 5:  # 合理范围内的推荐信数量\n",
    "                            extracted_numbers.append(num)\n",
    "            \n",
    "            # 如果找到了数字，返回最常见的数字\n",
    "            if extracted_numbers:\n",
    "                return max(set(extracted_numbers), key=extracted_numbers.count)\n",
    "            \n",
    "            # 如果没有找到明确的数字，检查是否有其他相关信息\n",
    "            return 'invalid'\n",
    "        \n",
    "        # 分类三个回答\n",
    "        classifications = []\n",
    "        response_details = []\n",
    "        \n",
    "        for i, response in enumerate([response_1, response_2, response_3], 1):\n",
    "            classification = classify_response(response)\n",
    "            classifications.append(classification)\n",
    "            response_details.append(f\"Response {i}: {classification} - {response[:100]}{'...' if len(response) > 100 else ''}\")\n",
    "        \n",
    "        # 过滤掉无效回答\n",
    "        valid_classifications = [c for c in classifications if c != 'invalid']\n",
    "        \n",
    "        # 进行判断\n",
    "        if len(valid_classifications) == 0:\n",
    "            # 所有回答都无效\n",
    "            final_decision = \"\"\n",
    "            decision_status = \"所有回答无效\"\n",
    "        elif len(valid_classifications) == 1:\n",
    "            # 只有一个有效回答\n",
    "            if valid_classifications[0] == 'no_explicit_demand':\n",
    "                final_decision = \"no explicit demand\"\n",
    "            else:\n",
    "                final_decision = f\"{valid_classifications[0]} letters of recommendation\"\n",
    "            decision_status = \"只有一个有效回答\"\n",
    "        else:\n",
    "            # 多个有效回答\n",
    "            # 分离数字回答和\"no explicit demand\"回答\n",
    "            numeric_answers = [c for c in valid_classifications if isinstance(c, int)]\n",
    "            no_demand_answers = [c for c in valid_classifications if c == 'no_explicit_demand']\n",
    "            \n",
    "            if len(no_demand_answers) == len(valid_classifications):\n",
    "                # 所有有效回答都是\"no explicit demand\"\n",
    "                final_decision = \"no explicit demand\"\n",
    "                decision_status = f\"所有{len(valid_classifications)}个有效回答都是no explicit demand\"\n",
    "            elif len(numeric_answers) == len(valid_classifications):\n",
    "                # 所有有效回答都是数字\n",
    "                if len(set(numeric_answers)) == 1:\n",
    "                    # 所有数字相同\n",
    "                    final_decision = f\"{numeric_answers[0]} letters of recommendation\"\n",
    "                    decision_status = f\"所有{len(valid_classifications)}个有效回答一致\"\n",
    "                else:\n",
    "                    # 数字不同，使用majority vote或取更高的数字\n",
    "                    vote_counts = Counter(numeric_answers)\n",
    "                    max_count = max(vote_counts.values())\n",
    "                    max_numbers = [num for num, count in vote_counts.items() if count == max_count]\n",
    "                    \n",
    "                    if len(max_numbers) == 1:\n",
    "                        # 有明确的majority\n",
    "                        final_decision = f\"{max_numbers[0]} letters of recommendation\"\n",
    "                        decision_status = f\"Majority vote: {max_numbers[0]} ({max_count}/{len(numeric_answers)})\"\n",
    "                    else:\n",
    "                        # 平票，取更高的数字\n",
    "                        final_number = max(max_numbers)\n",
    "                        final_decision = f\"{final_number} letters of recommendation\"\n",
    "                        decision_status = f\"平票情况，取更高数字: {final_number}\"\n",
    "            else:\n",
    "                # 混合回答（数字+no explicit demand）\n",
    "                if len(numeric_answers) >= len(no_demand_answers):\n",
    "                    # 数字回答更多或相等，使用数字结果\n",
    "                    if len(set(numeric_answers)) == 1:\n",
    "                        final_decision = f\"{numeric_answers[0]} letters of recommendation\"\n",
    "                        decision_status = f\"数字回答占主导，结果一致: {numeric_answers[0]}\"\n",
    "                    else:\n",
    "                        # 取更高的数字\n",
    "                        final_number = max(numeric_answers)\n",
    "                        final_decision = f\"{final_number} letters of recommendation\"\n",
    "                        decision_status = f\"数字回答占主导，取更高数字: {final_number}\"\n",
    "                else:\n",
    "                    # no explicit demand回答更多\n",
    "                    final_decision = \"no explicit demand\"\n",
    "                    decision_status = f\"no explicit demand回答占主导\"\n",
    "        \n",
    "        # 将所有信息合并\n",
    "        result = basic_info.copy()\n",
    "        result.update({\n",
    "            '推荐信': final_decision,\n",
    "            '判断状态': decision_status,\n",
    "            '有效回答数': len(valid_classifications),\n",
    "            '总回答数': len([r for r in [response_1, response_2, response_3] if r.strip()]),\n",
    "            'Response 1 分类': classifications[0],\n",
    "            'Response 2 分类': classifications[1],\n",
    "            'Response 3 分类': classifications[2],\n",
    "        })\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    # 转换为DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # 保存CSV文件到同一目录\n",
    "    output_dir = os.path.dirname(json_file_path)\n",
    "    csv_filename = os.path.basename(json_file_path).replace('.json', '_processed.csv')\n",
    "    output_path = os.path.join(output_dir, csv_filename)\n",
    "    \n",
    "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"处理完成！结果已保存到: {output_path}\")\n",
    "    print(f\"共处理 {len(df)} 条记录\")\n",
    "    print(f\"\\n推荐信需求分布:\")\n",
    "    print(df['推荐信'].value_counts(dropna=False))\n",
    "    print(f\"\\n判断状态分布:\")\n",
    "    print(df['判断状态'].value_counts())\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "df = extract_recommendation_letters_info(json_file_path)\n",
    "\n",
    "# 显示前几行数据预览\n",
    "print(\"\\n数据预览:\")\n",
    "print(df[['大学英文名称', '学位', '专业英文名称', '推荐信', '判断状态']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
