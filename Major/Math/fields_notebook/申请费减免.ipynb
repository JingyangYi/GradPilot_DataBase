{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454, 9)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/Major/Math')\n",
    "import asyncio\n",
    "from call_api import call_gemini, async_call_gemini\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "field_name = \"申请费减免\"\n",
    "field_path = f\"/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/Major/Math/fields_csv/{field_name}.csv\"\n",
    "field_df = pd.read_csv(field_path)\n",
    "\n",
    "field_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an assistant whose only task is to determine whether the graduate program below **offers an application-fee waiver**.\n",
    "\n",
    "────────────────────────────────────────────────────────\n",
    "How to verify\n",
    "\n",
    "1. **Use primary *.edu* sources only**  \n",
    "   • Review the Admissions and Program URLs supplied.  \n",
    "   • You may open other pages within the same university’s *.edu* domain (e.g., “Application Requirements”, “Fee Waiver”, “FAQ”).  \n",
    "   ⛔  Disregard all non-*.edu* sites, blogs, forums, press releases, or rankings.\n",
    "\n",
    "2. **Optional Google search**  \n",
    "   Query once:  \n",
    "   \"{university} {department} {degree} {program} application fee waiver site:.edu\"  \n",
    "   Check only *.edu* results until you find an authoritative statement.\n",
    "\n",
    "3. **Decision rules**  \n",
    "   • If any page clearly states that applicants **may obtain a fee waiver** under any condition, output **applicable**.  \n",
    "   • If a page explicitly says **no waivers are available**, output **not applicable**.  \n",
    "   • If neither situation is found, output **not mentioned**.  \n",
    "   • Never infer or invent; no citations or explanations are allowed.\n",
    "\n",
    "────────────────────────────────────────────────────────\n",
    "⚠️  Output format (exactly one line, all lowercase, no quotes, no extra text)\n",
    "\n",
    "applicable  \n",
    "not applicable  \n",
    "not mentioned  \n",
    "\n",
    "────────────────────────────────────────────────────────\n",
    "Pages to consult first:\n",
    "• Admissions URL: {admissions_url}  \n",
    "• Program URL:    {program_url}\n",
    "\n",
    "Does this program offer an application-fee waiver?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "# Async Gemini wrapper\n",
    "from call_api import async_call_gemini\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Concurrency guard – avoid hitting rate-limits\n",
    "# ---------------------------------------------------------------------------\n",
    "semaphore = asyncio.Semaphore(2)            # max concurrent rows\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Per-row worker\n",
    "# ---------------------------------------------------------------------------\n",
    "async def process_row(row, prompt_template, num_vote: int, model_name: str):\n",
    "    \"\"\"\n",
    "    1. Format the prompt for this row\n",
    "    2. Launch `num_vote` Gemini calls in parallel\n",
    "    3. Capture BOTH normal answers *and* every possible error case\n",
    "    4. Return a serialisable record\n",
    "    \"\"\"\n",
    "    async with semaphore:\n",
    "        row    = row.to_dict()\n",
    "        prompt = prompt_template.format(\n",
    "            university     = row[\"大学英文名称\"],\n",
    "            degree         = row[\"学位\"],\n",
    "            program        = row[\"专业英文名称\"],\n",
    "            department     = row[\"所属院系（英文）\"],\n",
    "            admissions_url = row[\"招生网址\"],\n",
    "            program_url    = row[\"专业网址\"],\n",
    "        )\n",
    "\n",
    "        record: dict = row.copy()\n",
    "        record[\"llm_reponses\"] = {}\n",
    "\n",
    "        # -------- launch Gemini calls in parallel --------------------\n",
    "        tasks = [\n",
    "            async_call_gemini(\n",
    "                prompt,\n",
    "                model_name=model_name,\n",
    "                use_search=True,\n",
    "                url_context=True\n",
    "            )\n",
    "            for _ in range(num_vote)\n",
    "        ]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "\n",
    "        # -------- post-process each response -------------------------\n",
    "        for i, response in enumerate(responses):\n",
    "            resp_key = f\"response {i+1}\"\n",
    "\n",
    "            # -- 1. Transport / server-side errors (string starting \"Error:\")\n",
    "            if isinstance(response, str) and response.startswith(\"Error:\"):\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": response                       # e.g. \"Error: 429 Rate limit …\"\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 2. Empty / malformed response objects\n",
    "            if not hasattr(response, \"candidates\") or not response.candidates:\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": \"No candidates returned\",\n",
    "                    \"raw_response\": str(response)\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 3. Extract main answer text\n",
    "            try:\n",
    "                text = response.candidates[0].content.parts[0].text\n",
    "            except Exception as e:\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": f\"Cannot parse text: {e}\",\n",
    "                    \"raw_response\": str(response)\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 4. Extract additional metadata (best-effort)\n",
    "            try:\n",
    "                url_context = str(response.candidates[0].url_context_metadata)\n",
    "            except Exception:\n",
    "                url_context = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_pages = (\n",
    "                    f\"Search Chunks: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.grounding_chunks}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_pages = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_queries = (\n",
    "                    f\"Search Query: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.web_search_queries}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_queries = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_support = (\n",
    "                    f\"Search Supports: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.groundingSupports}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_support = \"Not used\"\n",
    "\n",
    "            # -- 5. Store normal answer + metadata + raw object\n",
    "            record[\"llm_reponses\"][resp_key] = {\n",
    "                \"response_text\": text,\n",
    "                \"url_context\": url_context,\n",
    "                \"search_queries\": search_queries,\n",
    "                \"search_pages\": search_pages,\n",
    "                \"search_support\": search_support,\n",
    "                \"raw_response\": str(response)             # keep for deep-debugging\n",
    "            }\n",
    "\n",
    "        return record\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Batch orchestrator with tqdm progress bar\n",
    "# ---------------------------------------------------------------------------\n",
    "async def request_and_store_async(prompt_template,\n",
    "                                  field_df,\n",
    "                                  num_vote: int,\n",
    "                                  model_name: str,\n",
    "                                  start_from: int = 0,\n",
    "                                  end_at: int = -1):\n",
    "    \"\"\"\n",
    "    Runs `process_row` over the dataframe slice asynchronously,\n",
    "    shows a live tqdm bar, and dumps the results to JSON.\n",
    "    \"\"\"\n",
    "    df = field_df.copy()[start_from:end_at]\n",
    "\n",
    "    # Spawn tasks for every row in the slice\n",
    "    tasks = [\n",
    "        process_row(row, prompt_template, num_vote, model_name)\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # tqdm_asyncio.gather gives us progress updates as tasks complete\n",
    "    response_records = await tqdm_asyncio.gather(*tasks)\n",
    "\n",
    "    # Persist to disk ------------------------------------------------\n",
    "    output_dir = f\"../fields_records/{field_name}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = f\"{output_dir}/{field_name}_{model_name}_{start_from}_{end_at}.json\"\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(response_records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return response_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [1:00:09<00:00,  7.95s/it]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Only needed in Jupyter\n",
    "\n",
    "num_vote = 3\n",
    "start_from = 0\n",
    "end_at = len(field_df)\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "response_records = asyncio.run(\n",
    "    request_and_store_async(prompt_template, field_df, num_vote, model_name, start_from=start_from, end_at=end_at)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/Major/Math/fields_records/申请费减免/申请费减免_gemini-2.5-flash_0_454.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成！结果已保存到: /Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/Major/Math/fields_records/申请费减免/申请费减免_gemini-2.5-flash_0_454_processed.csv\n",
      "共处理 454 条记录\n",
      "\n",
      "申请费减免分布:\n",
      "申请费减免\n",
      "applicable        386\n",
      "                   46\n",
      "not applicable     22\n",
      "Name: count, dtype: int64\n",
      "\n",
      "判断状态分布:\n",
      "判断状态\n",
      "所有3个有效回答一致                                    275\n",
      "所有2个有效回答一致                                     82\n",
      "只有一个有效回答                                       41\n",
      "所有回答无效                                         40\n",
      "Majority vote: 2/3                             10\n",
      "平票: {'applicable': 1, 'not_applicable': 1}      3\n",
      "平票: {'not_applicable': 1, 'applicable': 1}      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "数据预览:\n",
      "                                  大学英文名称      学位  \\\n",
      "0                   Princeton University  Ph.D.    \n",
      "1                   Princeton University  Ph.D.    \n",
      "2  Massachusetts Institute of Technology     PhD   \n",
      "3  Massachusetts Institute of Technology     ScD   \n",
      "4                     Harvard University     PhD   \n",
      "5                     Harvard University     PhD   \n",
      "6                    Stanford University     PhD   \n",
      "7                    Stanford University      MS   \n",
      "8                    Stanford University      MS   \n",
      "9                    Stanford University     PhD   \n",
      "\n",
      "                                        专业英文名称       申请费减免        判断状态  \n",
      "0        Applied and Computational Mathematics  applicable    只有一个有效回答  \n",
      "1                                  Mathematics  applicable  所有2个有效回答一致  \n",
      "2                                  Mathematics  applicable  所有3个有效回答一致  \n",
      "3                                  Mathematics  applicable  所有3个有效回答一致  \n",
      "4                     Applied Mathematics SEAS  applicable  所有3个有效回答一致  \n",
      "5                                  Mathematics  applicable  所有3个有效回答一致  \n",
      "6  Computational and Mathematical Engineering   applicable  所有3个有效回答一致  \n",
      "7  Computational and Mathematical Engineering   applicable  所有3个有效回答一致  \n",
      "8       Mathematical and Computational Finance  applicable  所有2个有效回答一致  \n",
      "9                                 Mathematics   applicable  所有3个有效回答一致  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "def extract_fee_waiver_info(json_file_path):\n",
    "    \"\"\"\n",
    "    从JSON文件中提取申请费减免信息，使用majority vote判断\n",
    "    \n",
    "    Args:\n",
    "        json_file_path: JSON文件路径\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: 处理后的数据\n",
    "    \"\"\"\n",
    "    \n",
    "    # 读取JSON文件\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for record in data:\n",
    "        # 提取基本信息\n",
    "        basic_info = {\n",
    "            '大学英文名称': record.get('大学英文名称', '').strip(),\n",
    "            '学位': record.get('学位', ''),\n",
    "            '专业英文名称': record.get('专业英文名称', ''),\n",
    "            '所属院系': record.get('所属院系', ''),\n",
    "            '招生网址': record.get('招生网址', ''),\n",
    "            '专业网址': record.get('专业网址', ''),\n",
    "        }\n",
    "        \n",
    "        # 获取三个LLM responses\n",
    "        llm_responses = record.get('llm_reponses', {})\n",
    "        response_1 = llm_responses.get('response 1', {}).get('response_text', '').strip()\n",
    "        response_2 = llm_responses.get('response 2', {}).get('response_text', '').strip()\n",
    "        response_3 = llm_responses.get('response 3', {}).get('response_text', '').strip()\n",
    "        \n",
    "        # 分类每个回答\n",
    "        def classify_response(response_text):\n",
    "            \"\"\"\n",
    "            分类单个回答\n",
    "            返回: 'applicable', 'not_applicable', 'invalid'\n",
    "            \"\"\"\n",
    "            if not response_text or len(response_text.strip()) == 0:\n",
    "                return 'invalid'\n",
    "            \n",
    "            # 检查无效回答\n",
    "            invalid_patterns = [\n",
    "                r'^not found$',\n",
    "                r'^the\\b',  # 以\"The\"开头的长篇回答通常无效\n",
    "                r'^error',\n",
    "                r'^no data',\n",
    "                r'^unable to',\n",
    "                r'^cannot find'\n",
    "            ]\n",
    "            \n",
    "            response_lower = response_text.lower()\n",
    "            for pattern in invalid_patterns:\n",
    "                if re.search(pattern, response_lower, re.IGNORECASE):\n",
    "                    return 'invalid'\n",
    "            \n",
    "            # 检查\"not applicable\"（优先级更高）\n",
    "            if re.search(r'not applicable', response_lower, re.IGNORECASE):\n",
    "                return 'not_applicable'\n",
    "            \n",
    "            # 检查\"applicable\"\n",
    "            if re.search(r'applicable', response_lower, re.IGNORECASE):\n",
    "                return 'applicable'\n",
    "            \n",
    "            # 如果都没有匹配，视为无效\n",
    "            return 'invalid'\n",
    "        \n",
    "        # 分类三个回答\n",
    "        classifications = []\n",
    "        response_details = []\n",
    "        \n",
    "        for i, response in enumerate([response_1, response_2, response_3], 1):\n",
    "            classification = classify_response(response)\n",
    "            classifications.append(classification)\n",
    "            response_details.append(f\"Response {i}: {classification} - {response[:100]}{'...' if len(response) > 100 else ''}\")\n",
    "        \n",
    "        # 过滤掉无效回答\n",
    "        valid_classifications = [c for c in classifications if c != 'invalid']\n",
    "        \n",
    "        # 进行majority vote\n",
    "        if len(valid_classifications) == 0:\n",
    "            # 所有回答都无效\n",
    "            final_decision = \"\"\n",
    "            decision_status = \"所有回答无效\"\n",
    "        elif len(valid_classifications) == 1:\n",
    "            # 只有一个有效回答\n",
    "            final_decision = valid_classifications[0].replace('_', ' ')\n",
    "            decision_status = \"只有一个有效回答\"\n",
    "        else:\n",
    "            # 计算各类回答的数量\n",
    "            vote_counts = Counter(valid_classifications)\n",
    "            \n",
    "            if len(vote_counts) == 1:\n",
    "                # 所有有效回答一致\n",
    "                final_decision = list(vote_counts.keys())[0].replace('_', ' ')\n",
    "                decision_status = f\"所有{len(valid_classifications)}个有效回答一致\"\n",
    "            else:\n",
    "                # 回答不一致，检查是否有majority\n",
    "                max_count = max(vote_counts.values())\n",
    "                max_categories = [cat for cat, count in vote_counts.items() if count == max_count]\n",
    "                \n",
    "                if len(max_categories) == 1:\n",
    "                    # 有明确的majority\n",
    "                    final_decision = max_categories[0].replace('_', ' ')\n",
    "                    decision_status = f\"Majority vote: {max_count}/{len(valid_classifications)}\"\n",
    "                else:\n",
    "                    # 平票情况\n",
    "                    final_decision = \"\"\n",
    "                    decision_status = f\"平票: {dict(vote_counts)}\"\n",
    "        \n",
    "        # 将所有信息合并\n",
    "        result = basic_info.copy()\n",
    "        result.update({\n",
    "            '申请费减免': final_decision,\n",
    "            '判断状态': decision_status,\n",
    "            '有效回答数': len(valid_classifications),\n",
    "            '总回答数': len([r for r in [response_1, response_2, response_3] if r.strip()]),\n",
    "            'Response 1 分类': classify_response(response_1),\n",
    "            'Response 2 分类': classify_response(response_2),\n",
    "            'Response 3 分类': classify_response(response_3),\n",
    "        })\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    # 转换为DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # 保存CSV文件到同一目录\n",
    "    output_dir = os.path.dirname(json_file_path)\n",
    "    csv_filename = os.path.basename(json_file_path).replace('.json', '_processed.csv')\n",
    "    output_path = os.path.join(output_dir, csv_filename)\n",
    "    \n",
    "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"处理完成！结果已保存到: {output_path}\")\n",
    "    print(f\"共处理 {len(df)} 条记录\")\n",
    "    print(f\"\\n申请费减免分布:\")\n",
    "    print(df['申请费减免'].value_counts(dropna=False))\n",
    "    print(f\"\\n判断状态分布:\")\n",
    "    print(df['判断状态'].value_counts())\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = extract_fee_waiver_info(json_file_path)\n",
    "\n",
    "# 显示前几行数据预览\n",
    "print(\"\\n数据预览:\")\n",
    "print(df[['大学英文名称', '学位', '专业英文名称', '申请费减免', '判断状态']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
