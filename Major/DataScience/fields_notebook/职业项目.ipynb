{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/Users/yijingyang/Library/CloudStorage/OneDrive-ä¸ªäºº/GradPilot/ProgramDB/DataScience')\n",
    "import asyncio\n",
    "from call_api import call_gemini, async_call_gemini\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "field_name = \"èŒä¸šé¡¹ç›®\"\n",
    "field_path = f\"/Users/yijingyang/Library/CloudStorage/OneDrive-ä¸ªäºº/GradPilot/ProgramDB/DataScience/fields_csv/{field_name}.csv\"\n",
    "field_df = pd.read_csv(field_path)\n",
    "\n",
    "field_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an assistant who must classify the graduate program below as either **â€œprofessionalâ€** (career-focused) or **â€œnon-professionalâ€** (academic / research-oriented).\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ğŸ“Œ  What defines a *professional* program?\n",
    "â€¢ **Skill-centric curriculum** â€“ Courses concentrate on concrete industry tools and competencies (e.g., product management, data visualization, enterprise risk, UX design).  \n",
    "â€¢ **Limited research emphasis** â€“ Little or no mention of faculty-led research labs, theses, or publications; instead you see capstones, practicums, or internships.  \n",
    "â€¢ **Flexible delivery** â€“ Frequently online or hybrid, offered evenings/weekends, with multiple or rolling start dates (not just Fall) and variable part-time / full-time durations (â‰ˆ 9-24 months).  \n",
    "â€¢ **Career-first language** â€“ Website text highlights phrases like â€œadvance your career,â€ â€œtaught by industry experts,â€ â€œimmediate ROI,â€ â€œprofessional network,â€ â€œsalary growth,â€ etc.\n",
    "\n",
    "ğŸ”  Example programs (for context; do **not** classify these):\n",
    "1. Columbia University â€“ M.S. Enterprise Risk Management (School of Professional Studies)  \n",
    "2. Harvard Extension School â€“ A.L.M. in Management  \n",
    "3. NYU School of Professional Studies â€“ M.S. Integrated Marketing  \n",
    "4. Johns Hopkins Engineering for Professionals â€“ M.S. Cybersecurity  \n",
    "\n",
    "Unless the website clearly meets the criteria above, label the program **non-professional**.  \n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "âš ï¸  **Output format**  \n",
    "Return **exactly one line**: either  \n",
    "``professional``  \n",
    "or  \n",
    "``non-professional``  \n",
    "No additional words, punctuation, or explanations.\n",
    "\n",
    "Links to consult:  \n",
    "â€¢ Admissions URL: {admissions_url}  \n",
    "â€¢ Program URL: {program_url}\n",
    "\n",
    "Is this program a professional program?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "# Async Gemini wrapper\n",
    "from call_api import async_call_gemini\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Concurrency guard â€“ avoid hitting rate-limits\n",
    "# ---------------------------------------------------------------------------\n",
    "semaphore = asyncio.Semaphore(2)            # max concurrent rows\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Per-row worker\n",
    "# ---------------------------------------------------------------------------\n",
    "async def process_row(row, prompt_template, num_vote: int, model_name: str):\n",
    "    \"\"\"\n",
    "    1. Format the prompt for this row\n",
    "    2. Launch `num_vote` Gemini calls in parallel\n",
    "    3. Capture BOTH normal answers *and* every possible error case\n",
    "    4. Return a serialisable record\n",
    "    \"\"\"\n",
    "    async with semaphore:\n",
    "        row    = row.to_dict()\n",
    "        prompt = prompt_template.format(\n",
    "            university     = row[\"å¤§å­¦è‹±æ–‡åç§°\"],\n",
    "            degree         = row[\"å­¦ä½\"],\n",
    "            program        = row[\"ä¸“ä¸šè‹±æ–‡åç§°\"],\n",
    "            department     = row[\"æ‰€å±é™¢ç³»\"],\n",
    "            admissions_url = row[\"æ‹›ç”Ÿç½‘å€\"],\n",
    "            program_url    = row[\"ä¸“ä¸šç½‘å€\"],\n",
    "        )\n",
    "\n",
    "        record: dict = row.copy()\n",
    "        record[\"llm_reponses\"] = {}\n",
    "\n",
    "        # -------- launch Gemini calls in parallel --------------------\n",
    "        tasks = [\n",
    "            async_call_gemini(\n",
    "                prompt,\n",
    "                model_name=model_name,\n",
    "                use_search=True,\n",
    "                url_context=True\n",
    "            )\n",
    "            for _ in range(num_vote)\n",
    "        ]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "\n",
    "        # -------- post-process each response -------------------------\n",
    "        for i, response in enumerate(responses):\n",
    "            resp_key = f\"response {i+1}\"\n",
    "\n",
    "            # -- 1. Transport / server-side errors (string starting \"Error:\")\n",
    "            if isinstance(response, str) and response.startswith(\"Error:\"):\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": response                       # e.g. \"Error: 429 Rate limit â€¦\"\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 2. Empty / malformed response objects\n",
    "            if not hasattr(response, \"candidates\") or not response.candidates:\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": \"No candidates returned\",\n",
    "                    \"raw_response\": str(response)\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 3. Extract main answer text\n",
    "            try:\n",
    "                text = response.candidates[0].content.parts[0].text\n",
    "            except Exception as e:\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": f\"Cannot parse text: {e}\",\n",
    "                    \"raw_response\": str(response)\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 4. Extract additional metadata (best-effort)\n",
    "            try:\n",
    "                url_context = str(response.candidates[0].url_context_metadata)\n",
    "            except Exception:\n",
    "                url_context = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_pages = (\n",
    "                    f\"Search Chunks: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.grounding_chunks}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_pages = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_queries = (\n",
    "                    f\"Search Query: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.web_search_queries}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_queries = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_support = (\n",
    "                    f\"Search Supports: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.groundingSupports}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_support = \"Not used\"\n",
    "\n",
    "            # -- 5. Store normal answer + metadata + raw object\n",
    "            record[\"llm_reponses\"][resp_key] = {\n",
    "                \"response_text\": text,\n",
    "                \"url_context\": url_context,\n",
    "                \"search_queries\": search_queries,\n",
    "                \"search_pages\": search_pages,\n",
    "                \"search_support\": search_support,\n",
    "                \"raw_response\": str(response)             # keep for deep-debugging\n",
    "            }\n",
    "\n",
    "        return record\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Batch orchestrator with tqdm progress bar\n",
    "# ---------------------------------------------------------------------------\n",
    "async def request_and_store_async(prompt_template,\n",
    "                                  field_df,\n",
    "                                  num_vote: int,\n",
    "                                  model_name: str,\n",
    "                                  start_from: int = 0,\n",
    "                                  end_at: int = -1):\n",
    "    \"\"\"\n",
    "    Runs `process_row` over the dataframe slice asynchronously,\n",
    "    shows a live tqdm bar, and dumps the results to JSON.\n",
    "    \"\"\"\n",
    "    df = field_df.copy()[start_from:end_at]\n",
    "\n",
    "    # Spawn tasks for every row in the slice\n",
    "    tasks = [\n",
    "        process_row(row, prompt_template, num_vote, model_name)\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # tqdm_asyncio.gather gives us progress updates as tasks complete\n",
    "    response_records = await tqdm_asyncio.gather(*tasks)\n",
    "\n",
    "    # Persist to disk ------------------------------------------------\n",
    "    output_dir = f\"../fields_records/{field_name}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = f\"{output_dir}/{field_name}_{model_name}_{start_from}_{end_at}.json\"\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(response_records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return response_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 350/350 [1:22:28<00:00, 14.14s/it]    \n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Only needed in Jupyter\n",
    "\n",
    "num_vote = 3\n",
    "start_from = 0\n",
    "end_at = -1\n",
    "model_name = \"gemini-2.5-pro\"\n",
    "response_records = asyncio.run(\n",
    "    request_and_store_async(prompt_template, field_df, num_vote, model_name, start_from=start_from, end_at=end_at)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯»å–æ–‡ä»¶: /Users/yijingyang/Library/CloudStorage/OneDrive-ä¸ªäºº/GradPilot/ProgramDB/DataScience/fields_records/èŒä¸šé¡¹ç›®/èŒä¸šé¡¹ç›®_gemini-2.5-pro_0_-1.json\n",
      "æ€»é¡¹ç›®æ•°: 350\n",
      "å‘ç°æ— æ•ˆå›ç­”: 361 ä¸ª\n",
      "å¼€å§‹ä¿®å¤ 361 ä¸ªæ— æ•ˆå›ç­”...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/361 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 361/361 [43:14<00:00,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ä¿®å¤å®Œæˆ!\n",
      "æ€»å›ç­”æ•°: 1050\n",
      "æ— æ•ˆå›ç­”æ•°: 361\n",
      "æˆåŠŸä¿®å¤: 357\n",
      "ä¿®å¤å¤±è´¥: 4\n",
      "ä¿®å¤æˆåŠŸç‡: 98.9%\n",
      "\n",
      "é‡è¯•ç»Ÿè®¡:\n",
      "ç¬¬1æ¬¡å°è¯•: 320 ä¸ªå›ç­”\n",
      "ç¬¬2æ¬¡å°è¯•: 33 ä¸ªå›ç­”\n",
      "ç¬¬3æ¬¡å°è¯•: 8 ä¸ªå›ç­”\n",
      "\n",
      "ä¿®å¤åçš„æ–‡ä»¶å·²ä¿å­˜åˆ°: /Users/yijingyang/Library/CloudStorage/OneDrive-ä¸ªäºº/GradPilot/ProgramDB/DataScience/fields_records/èŒä¸šé¡¹ç›®/èŒä¸šé¡¹ç›®_gemini-2.5-pro_0_-1_fixed.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import asyncio\n",
    "from call_api import async_call_gemini\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "async def fill_invalid_responses(json_file_path, prompt_template, validation_func, \n",
    "                                model_name=\"gemini-2.5-flash\", max_retries=2):\n",
    "    \"\"\"\n",
    "    æ£€æŸ¥JSONæ–‡ä»¶ä¸­çš„æ— æ•ˆå›ç­”å¹¶é‡æ–°è¯·æ±‚ï¼Œç›´åˆ°è·å¾—åˆæ³•å›ç­”\n",
    "    \n",
    "    Args:\n",
    "        json_file_path (str): JSONæ–‡ä»¶è·¯å¾„\n",
    "        prompt_template (str): æç¤ºè¯æ¨¡æ¿\n",
    "        validation_func (function): éªŒè¯å‡½æ•°ï¼Œè¿”å›(is_valid, status)\n",
    "        model_name (str): æ¨¡å‹åç§°\n",
    "        max_retries (int): æœ€å¤§é‡è¯•æ¬¡æ•°\n",
    "    \n",
    "    Returns:\n",
    "        dict: å¤„ç†ç»Ÿè®¡ä¿¡æ¯\n",
    "    \"\"\"\n",
    "    \n",
    "    def is_valid_professional_response(response_text):\n",
    "        \"\"\"éªŒè¯èŒä¸šé¡¹ç›®åˆ†ç±»å›ç­”æ˜¯å¦åˆæ³•\"\"\"\n",
    "        if not response_text or response_text.strip() == \"\":\n",
    "            return False, \"ç©ºç™½å›ç­”\"\n",
    "        \n",
    "        response_clean = response_text.strip().lower()\n",
    "        \n",
    "        if len(response_text) > 100:\n",
    "            return False, \"å›ç­”è¿‡é•¿\"\n",
    "        \n",
    "        if response_clean in [\"professional\", \"non-professional\"]:\n",
    "            return True, \"æœ‰æ•ˆå›ç­”\"\n",
    "        \n",
    "        return False, \"æ— æ•ˆåˆ†ç±»\"\n",
    "    \n",
    "    async def get_new_response(prompt):\n",
    "        \"\"\"è·å–æ–°çš„å›ç­”\"\"\"\n",
    "        try:\n",
    "            response = await async_call_gemini(\n",
    "                prompt,\n",
    "                model_name=model_name,\n",
    "                use_search=True,\n",
    "                url_context=True\n",
    "            )\n",
    "            \n",
    "            # å¤„ç†é”™è¯¯å“åº”\n",
    "            if isinstance(response, str) and response.startswith(\"Error:\"):\n",
    "                return None, f\"APIé”™è¯¯: {response}\"\n",
    "            \n",
    "            # å¤„ç†ç©ºå“åº”\n",
    "            if not hasattr(response, \"candidates\") or not response.candidates:\n",
    "                return None, \"æ— candidates\"\n",
    "            \n",
    "            # æå–å›ç­”æ–‡æœ¬\n",
    "            try:\n",
    "                text = response.candidates[0].content.parts[0].text\n",
    "                return text, \"æˆåŠŸè·å–\"\n",
    "            except Exception as e:\n",
    "                return None, f\"è§£æå¤±è´¥: {e}\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return None, f\"è¯·æ±‚å¼‚å¸¸: {e}\"\n",
    "    \n",
    "    # è¯»å–JSONæ–‡ä»¶\n",
    "    print(f\"è¯»å–æ–‡ä»¶: {json_file_path}\")\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(f\"æ€»é¡¹ç›®æ•°: {len(data)}\")\n",
    "    \n",
    "    # ç»Ÿè®¡ä¿¡æ¯\n",
    "    stats = {\n",
    "        'total_projects': len(data),\n",
    "        'total_responses': 0,\n",
    "        'invalid_responses': 0,\n",
    "        'fixed_responses': 0,\n",
    "        'failed_fixes': 0,\n",
    "        'retry_stats': {}\n",
    "    }\n",
    "    \n",
    "    # æ”¶é›†æ‰€æœ‰éœ€è¦ä¿®å¤çš„é¡¹ç›®\n",
    "    projects_to_fix = []\n",
    "    \n",
    "    for i, project in enumerate(data):\n",
    "        llm_responses = project.get('llm_reponses', {})\n",
    "        \n",
    "        for resp_key, resp_data in llm_responses.items():\n",
    "            stats['total_responses'] += 1\n",
    "            \n",
    "            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨response_textå­—æ®µ\n",
    "            if 'response_text' not in resp_data:\n",
    "                # å¦‚æœæ²¡æœ‰response_textï¼Œå¯èƒ½æ˜¯é”™è¯¯å“åº”ï¼Œæ ‡è®°ä¸ºéœ€è¦ä¿®å¤\n",
    "                stats['invalid_responses'] += 1\n",
    "                projects_to_fix.append((i, resp_key, project))\n",
    "                continue\n",
    "            \n",
    "            # éªŒè¯å›ç­”æœ‰æ•ˆæ€§\n",
    "            response_text = resp_data.get('response_text', '')\n",
    "            is_valid, status = validation_func(response_text)\n",
    "            \n",
    "            if not is_valid:\n",
    "                stats['invalid_responses'] += 1\n",
    "                projects_to_fix.append((i, resp_key, project))\n",
    "    \n",
    "    print(f\"å‘ç°æ— æ•ˆå›ç­”: {stats['invalid_responses']} ä¸ª\")\n",
    "    \n",
    "    if not projects_to_fix:\n",
    "        print(\"æ‰€æœ‰å›ç­”éƒ½æ˜¯æœ‰æ•ˆçš„ï¼Œæ— éœ€ä¿®å¤\")\n",
    "        return stats\n",
    "    \n",
    "    # é™åˆ¶å¹¶å‘æ•°\n",
    "    semaphore = asyncio.Semaphore(2)\n",
    "    \n",
    "    async def fix_single_response(project_index, resp_key, project):\n",
    "        \"\"\"ä¿®å¤å•ä¸ªå›ç­”\"\"\"\n",
    "        async with semaphore:\n",
    "            # æ„å»ºæç¤ºè¯\n",
    "            prompt = prompt_template.format(\n",
    "                university=project[\"å¤§å­¦è‹±æ–‡åç§°\"],\n",
    "                degree=project[\"å­¦ä½\"],\n",
    "                program=project[\"ä¸“ä¸šè‹±æ–‡åç§°\"],\n",
    "                department=project[\"æ‰€å±é™¢ç³»\"],\n",
    "                admissions_url=project[\"æ‹›ç”Ÿç½‘å€\"],\n",
    "                program_url=project[\"ä¸“ä¸šç½‘å€\"],\n",
    "            )\n",
    "            \n",
    "            for retry_count in range(1, max_retries + 2):  # +1 å› ä¸ºä»1å¼€å§‹è®¡æ•°\n",
    "                new_text, status = await get_new_response(prompt)\n",
    "                \n",
    "                if new_text is None:\n",
    "                    if retry_count <= max_retries:\n",
    "                        await asyncio.sleep(1)  # çŸ­æš‚å»¶è¿Ÿ\n",
    "                        continue\n",
    "                    else:\n",
    "                        # æœ€ç»ˆå¤±è´¥\n",
    "                        return project_index, resp_key, None, f\"ä¿®å¤å¤±è´¥: {status}\", retry_count\n",
    "                \n",
    "                # éªŒè¯æ–°å›ç­”\n",
    "                is_valid, validation_status = validation_func(new_text)\n",
    "                \n",
    "                if is_valid:\n",
    "                    # æˆåŠŸè·å¾—æœ‰æ•ˆå›ç­”\n",
    "                    return project_index, resp_key, new_text, f\"ä¿®å¤æˆåŠŸ(ç¬¬{retry_count}æ¬¡å°è¯•)\", retry_count\n",
    "                else:\n",
    "                    if retry_count <= max_retries:\n",
    "                        await asyncio.sleep(1)\n",
    "                        continue\n",
    "                    else:\n",
    "                        # é‡è¯•æ¬¡æ•°ç”¨å®Œä½†ä»æ— æ•ˆ\n",
    "                        return project_index, resp_key, new_text, f\"ä¿®å¤å¤±è´¥: {validation_status}\", retry_count\n",
    "            \n",
    "            return project_index, resp_key, None, \"æ„å¤–é”™è¯¯\", max_retries + 1\n",
    "    \n",
    "    # å¹¶è¡Œä¿®å¤æ‰€æœ‰æ— æ•ˆå›ç­”\n",
    "    print(f\"å¼€å§‹ä¿®å¤ {len(projects_to_fix)} ä¸ªæ— æ•ˆå›ç­”...\")\n",
    "    \n",
    "    tasks = [\n",
    "        fix_single_response(project_index, resp_key, project)\n",
    "        for project_index, resp_key, project in projects_to_fix\n",
    "    ]\n",
    "    \n",
    "    results = await tqdm_asyncio.gather(*tasks)\n",
    "    \n",
    "    # æ›´æ–°æ•°æ®å’Œç»Ÿè®¡\n",
    "    for project_index, resp_key, new_text, status, retry_count in results:\n",
    "        # æ›´æ–°é‡è¯•ç»Ÿè®¡\n",
    "        if retry_count not in stats['retry_stats']:\n",
    "            stats['retry_stats'][retry_count] = 0\n",
    "        stats['retry_stats'][retry_count] += 1\n",
    "        \n",
    "        if new_text is not None and \"ä¿®å¤æˆåŠŸ\" in status:\n",
    "            # æ›´æ–°åŸå§‹æ•°æ®\n",
    "            data[project_index]['llm_reponses'][resp_key]['response_text'] = new_text\n",
    "            data[project_index]['llm_reponses'][resp_key]['fix_status'] = status\n",
    "            data[project_index]['llm_reponses'][resp_key]['fix_attempts'] = retry_count\n",
    "            stats['fixed_responses'] += 1\n",
    "        else:\n",
    "            # ä¿®å¤å¤±è´¥ï¼Œæ ‡è®°çŠ¶æ€\n",
    "            data[project_index]['llm_reponses'][resp_key]['fix_status'] = status\n",
    "            data[project_index]['llm_reponses'][resp_key]['fix_attempts'] = retry_count\n",
    "            stats['failed_fixes'] += 1\n",
    "    \n",
    "    # ä¿å­˜ä¿®å¤åçš„æ–‡ä»¶\n",
    "    output_path = json_file_path.replace('.json', '_fixed.json')\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯\n",
    "    print(f\"\\nä¿®å¤å®Œæˆ!\")\n",
    "    print(f\"æ€»å›ç­”æ•°: {stats['total_responses']}\")\n",
    "    print(f\"æ— æ•ˆå›ç­”æ•°: {stats['invalid_responses']}\")\n",
    "    print(f\"æˆåŠŸä¿®å¤: {stats['fixed_responses']}\")\n",
    "    print(f\"ä¿®å¤å¤±è´¥: {stats['failed_fixes']}\")\n",
    "    print(f\"ä¿®å¤æˆåŠŸç‡: {stats['fixed_responses']/stats['invalid_responses']*100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\né‡è¯•ç»Ÿè®¡:\")\n",
    "    for attempts, count in stats['retry_stats'].items():\n",
    "        print(f\"ç¬¬{attempts}æ¬¡å°è¯•: {count} ä¸ªå›ç­”\")\n",
    "    \n",
    "    print(f\"\\nä¿®å¤åçš„æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_path}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹ - èŒä¸šé¡¹ç›®åˆ†ç±»\n",
    "async def fix_professional_classification():\n",
    "    \"\"\"ä¿®å¤èŒä¸šé¡¹ç›®åˆ†ç±»çš„æ— æ•ˆå›ç­”\"\"\"\n",
    "    \n",
    "    def is_valid_professional_response(response_text):\n",
    "        \"\"\"éªŒè¯èŒä¸šé¡¹ç›®åˆ†ç±»å›ç­”æ˜¯å¦åˆæ³•\"\"\"\n",
    "        if not response_text or response_text.strip() == \"\":\n",
    "            return False, \"ç©ºç™½å›ç­”\"\n",
    "        \n",
    "        response_clean = response_text.strip().lower()\n",
    "        \n",
    "        if len(response_text) > 100:\n",
    "            return False, \"å›ç­”è¿‡é•¿\"\n",
    "        \n",
    "        if response_clean in [\"professional\", \"non-professional\"]:\n",
    "            return True, \"æœ‰æ•ˆå›ç­”\"\n",
    "        \n",
    "        return False, \"æ— æ•ˆåˆ†ç±»\"\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "You are an assistant who must classify the graduate program below as either **\"professional\"** (career-focused) or **\"non-professional\"** (academic / research-oriented).\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ğŸ“Œ  What defines a *professional* program?\n",
    "â€¢ **Skill-centric curriculum** â€“ Courses concentrate on concrete industry tools and competencies (e.g., product management, data visualization, enterprise risk, UX design).  \n",
    "â€¢ **Limited research emphasis** â€“ Little or no mention of faculty-led research labs, theses, or publications; instead you see capstones, practicums, or internships.  \n",
    "â€¢ **Flexible delivery** â€“ Frequently online or hybrid, offered evenings/weekends, with multiple or rolling start dates (not just Fall) and variable part-time / full-time durations (â‰ˆ 9-24 months).  \n",
    "â€¢ **Career-first language** â€“ Website text highlights phrases like \"advance your career,\" \"taught by industry experts,\" \"immediate ROI,\" \"professional network,\" \"salary growth,\" etc.\n",
    "\n",
    "ğŸ”  Example programs (for context; do **not** classify these):\n",
    "1. Columbia University â€“ M.S. Enterprise Risk Management (School of Professional Studies)  \n",
    "2. Harvard Extension School â€“ A.L.M. in Management  \n",
    "3. NYU School of Professional Studies â€“ M.S. Integrated Marketing  \n",
    "4. Johns Hopkins Engineering for Professionals â€“ M.S. Cybersecurity  \n",
    "\n",
    "Unless the website clearly meets the criteria above, label the program **non-professional**.  \n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "âš ï¸  **Output format**  \n",
    "Return **exactly one line**: either  \n",
    "``professional``  \n",
    "or  \n",
    "``non-professional``  \n",
    "No additional words, punctuation, or explanations.\n",
    "\n",
    "Links to consult:  \n",
    "â€¢ Admissions URL: {admissions_url}  \n",
    "â€¢ Program URL: {program_url}\n",
    "\n",
    "Is this program a professional program?\n",
    "\"\"\"\n",
    "\n",
    "    json_file_path = \"/Users/yijingyang/Library/CloudStorage/OneDrive-ä¸ªäºº/GradPilot/ProgramDB/DataScience/fields_records/èŒä¸šé¡¹ç›®/èŒä¸šé¡¹ç›®_gemini-2.5-pro_0_-1.json\"\n",
    "    \n",
    "    stats = await fill_invalid_responses(\n",
    "        json_file_path=json_file_path,\n",
    "        prompt_template=prompt_template,\n",
    "        validation_func=is_valid_professional_response,\n",
    "        model_name=\"gemini-2.5-flash\",\n",
    "        max_retries=2\n",
    "    )\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# è¿è¡Œä¿®å¤\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# æ‰§è¡Œä¿®å¤\n",
    "stats = asyncio.run(fix_professional_classification())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "èŒä¸šé¡¹ç›®åˆ†ç±»ç»Ÿè®¡:\n",
      "æ€»é¡¹ç›®æ•°: 350\n",
      "ä¸€è‡´è®¤ä¸ºæ˜¯professional: 170 (48.6%)\n",
      "ä¸€è‡´è®¤ä¸ºæ˜¯non-professional: 130 (37.1%)\n",
      "å¤šæ•°ç¥¨professional: 25 (7.1%)\n",
      "å¤šæ•°ç¥¨non-professional: 25 (7.1%)\n",
      "ç¥¨æ•°ç›¸ç­‰: 0 (0.0%)\n",
      "æ‰€æœ‰å›ç­”å‡æ— æ•ˆ: 0 (0.0%)\n",
      "æ€»æœ‰æ•ˆå›ç­”æ•°: 1046\n",
      "æ€»æ— æ•ˆå›ç­”æ•°: 4\n",
      "å¹³å‡æ¯é¡¹ç›®æœ‰æ•ˆå›ç­”æ•°: 2.99\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def process_professional_classification(json_file_path, output_csv_path):\n",
    "    \"\"\"\n",
    "    Process professional/non-professional classification from JSON file with majority voting.\n",
    "    \n",
    "    Args:\n",
    "        json_file_path (str): Path to the JSON file containing professional classification data\n",
    "        output_csv_path (str): Path to save the output CSV file\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with classification results and statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    def is_valid_response(response_text):\n",
    "        \"\"\"Check if a response is valid (professional or non-professional)\"\"\"\n",
    "        if not response_text or response_text.strip() == \"\":\n",
    "            return False, \"ç©ºç™½å›ç­”\"\n",
    "        \n",
    "        response_clean = response_text.strip().lower()\n",
    "        \n",
    "        # Check for overly long responses (likely explanatory text rather than classification)\n",
    "        if len(response_text) > 100:\n",
    "            return False, \"å›ç­”è¿‡é•¿\"\n",
    "        \n",
    "        # Check if response is exactly one of the two valid classifications\n",
    "        if response_clean in [\"professional\", \"non-professional\"]:\n",
    "            return True, \"æœ‰æ•ˆå›ç­”\"\n",
    "        \n",
    "        return False, \"æ— æ•ˆåˆ†ç±»\"\n",
    "    \n",
    "    # Load JSON data\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    results = []\n",
    "    stats = {\n",
    "        'total_programs': 0,\n",
    "        'unanimous_professional': 0,\n",
    "        'unanimous_non_professional': 0,\n",
    "        'majority_professional': 0,\n",
    "        'majority_non_professional': 0,\n",
    "        'tied_votes': 0,\n",
    "        'all_invalid': 0,\n",
    "        'total_valid_responses': 0,\n",
    "        'total_invalid_responses': 0\n",
    "    }\n",
    "    \n",
    "    for program in data:\n",
    "        stats['total_programs'] += 1\n",
    "        \n",
    "        # Extract basic info\n",
    "        university = program.get('å¤§å­¦è‹±æ–‡åç§°', '')\n",
    "        degree = program.get('å­¦ä½', '')\n",
    "        major = program.get('ä¸“ä¸šè‹±æ–‡åç§°', '')\n",
    "        school = program.get('æ‰€å±é™¢ç³»', '')\n",
    "        \n",
    "        # Extract responses\n",
    "        llm_responses = program.get('llm_reponses', {})\n",
    "        \n",
    "        # Process each response\n",
    "        response_data = {}\n",
    "        valid_responses = []\n",
    "        \n",
    "        for response_num in range(1, 4):\n",
    "            response_key = f\"response {response_num}\"\n",
    "            response_text = \"\"\n",
    "            \n",
    "            if response_key in llm_responses:\n",
    "                response_text = llm_responses[response_key].get('response_text', '')\n",
    "            \n",
    "            # Validate response\n",
    "            is_valid, status = is_valid_response(response_text)\n",
    "            \n",
    "            # Store response details\n",
    "            response_data[f'response_{response_num}_text'] = response_text\n",
    "            response_data[f'response_{response_num}_status'] = status\n",
    "            response_data[f'response_{response_num}_valid'] = is_valid\n",
    "            \n",
    "            # Add to valid responses if valid\n",
    "            if is_valid:\n",
    "                valid_responses.append(response_text.strip().lower())\n",
    "        \n",
    "        # Count valid and invalid responses\n",
    "        valid_count = len(valid_responses)\n",
    "        invalid_count = 3 - valid_count\n",
    "        stats['total_valid_responses'] += valid_count\n",
    "        stats['total_invalid_responses'] += invalid_count\n",
    "        \n",
    "        # Determine final classification\n",
    "        if valid_count == 0:\n",
    "            final_classification = \"éœ€è¦é¢å¤–ç¡®è®¤\"\n",
    "            voting_status = \"æ‰€æœ‰å›ç­”å‡æ— æ•ˆ\"\n",
    "            stats['all_invalid'] += 1\n",
    "        else:\n",
    "            # Count votes\n",
    "            vote_counts = Counter(valid_responses)\n",
    "            professional_votes = vote_counts.get('professional', 0)\n",
    "            non_professional_votes = vote_counts.get('non-professional', 0)\n",
    "            \n",
    "            if professional_votes == non_professional_votes:\n",
    "                # Tie\n",
    "                final_classification = \"éœ€è¦é¢å¤–ç¡®è®¤\"\n",
    "                voting_status = f\"ç¥¨æ•°ç›¸ç­‰({professional_votes}ç¥¨professional vs {non_professional_votes}ç¥¨non-professional)\"\n",
    "                stats['tied_votes'] += 1\n",
    "            elif professional_votes > non_professional_votes:\n",
    "                final_classification = 'professional'\n",
    "                if valid_count == professional_votes:  # All valid votes are professional\n",
    "                    voting_status = f\"ä¸€è‡´æŠ•ç¥¨({valid_count}/3æœ‰æ•ˆ)\"\n",
    "                    stats['unanimous_professional'] += 1\n",
    "                else:\n",
    "                    voting_status = f\"å¤šæ•°ç¥¨({professional_votes}ç¥¨professional vs {non_professional_votes}ç¥¨non-professional)\"\n",
    "                    stats['majority_professional'] += 1\n",
    "            else:  # non_professional_votes > professional_votes\n",
    "                final_classification = 'non-professional'\n",
    "                if valid_count == non_professional_votes:  # All valid votes are non-professional\n",
    "                    voting_status = f\"ä¸€è‡´æŠ•ç¥¨({valid_count}/3æœ‰æ•ˆ)\"\n",
    "                    stats['unanimous_non_professional'] += 1\n",
    "                else:\n",
    "                    voting_status = f\"å¤šæ•°ç¥¨({non_professional_votes}ç¥¨non-professional vs {professional_votes}ç¥¨professional)\"\n",
    "                    stats['majority_non_professional'] += 1\n",
    "        \n",
    "        # Create result record\n",
    "        result_record = {\n",
    "            'å¤§å­¦è‹±æ–‡åç§°': university,\n",
    "            'å­¦ä½': degree,\n",
    "            'ä¸“ä¸šè‹±æ–‡åç§°': major,\n",
    "            'æ‰€å±é™¢ç³»': school,\n",
    "            'èŒä¸šé¡¹ç›®': final_classification,\n",
    "            'æŠ•ç¥¨çŠ¶æ€': voting_status\n",
    "        }\n",
    "        \n",
    "        # Add response details\n",
    "        result_record.update(response_data)\n",
    "        \n",
    "        results.append(result_record)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"èŒä¸šé¡¹ç›®åˆ†ç±»ç»Ÿè®¡:\")\n",
    "    print(f\"æ€»é¡¹ç›®æ•°: {stats['total_programs']}\")\n",
    "    print(f\"ä¸€è‡´è®¤ä¸ºæ˜¯professional: {stats['unanimous_professional']} ({stats['unanimous_professional']/stats['total_programs']*100:.1f}%)\")\n",
    "    print(f\"ä¸€è‡´è®¤ä¸ºæ˜¯non-professional: {stats['unanimous_non_professional']} ({stats['unanimous_non_professional']/stats['total_programs']*100:.1f}%)\")\n",
    "    print(f\"å¤šæ•°ç¥¨professional: {stats['majority_professional']} ({stats['majority_professional']/stats['total_programs']*100:.1f}%)\")\n",
    "    print(f\"å¤šæ•°ç¥¨non-professional: {stats['majority_non_professional']} ({stats['majority_non_professional']/stats['total_programs']*100:.1f}%)\")\n",
    "    print(f\"ç¥¨æ•°ç›¸ç­‰: {stats['tied_votes']} ({stats['tied_votes']/stats['total_programs']*100:.1f}%)\")\n",
    "    print(f\"æ‰€æœ‰å›ç­”å‡æ— æ•ˆ: {stats['all_invalid']} ({stats['all_invalid']/stats['total_programs']*100:.1f}%)\")\n",
    "    print(f\"æ€»æœ‰æ•ˆå›ç­”æ•°: {stats['total_valid_responses']}\")\n",
    "    print(f\"æ€»æ— æ•ˆå›ç­”æ•°: {stats['total_invalid_responses']}\")\n",
    "    \n",
    "    if stats['total_programs'] > 0:\n",
    "        print(f\"å¹³å‡æ¯é¡¹ç›®æœ‰æ•ˆå›ç­”æ•°: {stats['total_valid_responses']/stats['total_programs']:.2f}\")\n",
    "    \n",
    "    return df, stats\n",
    "\n",
    "# Usage:\n",
    "df, stats = process_professional_classification(\n",
    "    '/Users/yijingyang/Library/CloudStorage/OneDrive-ä¸ªäºº/GradPilot/ProgramDB/DataScience/fields_records/èŒä¸šé¡¹ç›®/èŒä¸šé¡¹ç›®_gemini-2.5-pro_0_-1_fixed.json',\n",
    "    '/Users/yijingyang/Library/CloudStorage/OneDrive-ä¸ªäºº/GradPilot/ProgramDB/DataScience/fields_records/èŒä¸šé¡¹ç›®.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
