# 爬虫技术方案

## 技术栈
- Scrapy + scrapy-playwright
- Redis（去重、任务队列）
- Python 3.8+

## 输入
- program_urls.csv（项目根URL）

## 爬取策略
- 深度：2层（根URL + 子链接）
- 并发：20个请求/秒
- 重试：3次，指数退避

## 输出格式
每个项目生成独立JSON文件：`{program_name}_{source_file}.json`

```json
{
  "project_id": "项目ID",
  "root_url": "根URL",
  "crawl_time": "2024-01-01T12:00:00Z",
  "pages": [
    {
      "url": "页面URL",
      "level": 1,
      "title": "页面标题", 
      "content": "提取的文本内容",
      "links": ["子链接1", "子链接2"]
    }
  ],
  "total_pages": 15,
  "status": "completed"
}
```

## 关键配置
- USER_AGENT轮换
- 请求间隔：随机0.5-2秒
- 超时：30秒
- 内容过滤：只保留英文页面
- 文件大小限制：50MB/项目