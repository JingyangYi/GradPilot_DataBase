# 项目URL爬虫

## 安装依赖
```bash
pip install -r requirements.txt
```

## 运行模式

### 测试模式（推荐）
爬取15个随机选择的项目，用于测试和调试：
```bash
python run_crawler.py --test
```
- 自动生成 `test_urls.csv`（如果不存在）
- 适合开发和测试阶段

### 完整模式
爬取所有12,486个项目：
```bash
python run_crawler.py
```
- 使用 `program_urls.csv`
- 适合正式数据收集

### 自定义文件模式
使用指定的CSV文件：
```bash
python run_crawler.py --csv-file your_custom_urls.csv
```

## 输出
- 结果保存在 `output/` 目录
- 每个项目生成一个JSON文件：`{program_name}_{source_file}.json`

## 配置参数
- **爬取深度**：2层（根URL + 子链接）
- **并发请求**：20个/秒
- **请求延时**：1秒（±0.5秒随机）
- **重试次数**：3次
- **URL过滤**：47个关键词黑名单
- **域名限制**：只爬取同域名页面

## 测试项目预览
当前测试列表包含15个项目，涵盖不同地区和专业：
- 南安普顿大学语言与文化文学硕士
- 佛罗里达大学生物医学工程理学硕士
- 香港中文大学新闻学文学硕士
- 莫纳什大学文化与创意产业硕士
- 等等...

## 注意事项
- 测试模式建议首次使用，验证爬虫功能
- 爬取过程中可用 Ctrl+C 随时中断
- 确保网络连接稳定
- 建议非高峰时段运行完整模式