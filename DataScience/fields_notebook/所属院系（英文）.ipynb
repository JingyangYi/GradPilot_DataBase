{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 7)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/DataScience')\n",
    "import asyncio\n",
    "from call_api import call_gemini, async_call_gemini\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "field_name = \"所属院系（英文）\"\n",
    "field_path = f\"/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/DataScience/fields_csv/{field_name}.csv\"\n",
    "field_df = pd.read_csv(field_path)\n",
    "\n",
    "field_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an assistant whose only task is to identify the **school / college / faculty** that houses the graduate program below and return its official homepage URL.\n",
    "\n",
    "────────────────────────────────────────────────────────\n",
    "How to find the information  \n",
    "\n",
    "1. **Primary *.edu* sources only**  \n",
    "   • Inspect the Admissions and Program URLs provided.  \n",
    "   • Open additional pages within the same university’s *.edu* domain (e.g., “About the School”, “Departments”).  \n",
    "   ⛔  Ignore non-*.edu* sites, blogs, rankings, or third-party profiles.\n",
    "\n",
    "2. **Optional Google search**  \n",
    "   Single query:  \n",
    "   \"{university} {degree} {program} school college site:.edu\"  \n",
    "   Check only *.edu* results until you locate the school’s homepage.\n",
    "\n",
    "3. **Selection rules**  \n",
    "   • Capture *one* clear school/college name (e.g., “School of Engineering and Applied Science”).  \n",
    "   • Copy the most authoritative homepage URL for that school (https://…).  \n",
    "   • If no reliable *.edu* source identifies the school, output **Not found**.  \n",
    "   • Never invent.\n",
    "\n",
    "────────────────────────────────────────────────────────\n",
    "⚠️  Output format (exactly one line, no quotes, no extra text)  \n",
    "\n",
    "<School / College Name>, <URL>  \n",
    "or  \n",
    "Not found  \n",
    "\n",
    "Examples of valid outputs:  \n",
    "School of Engineering and Applied Science, https://engineering.columbia.edu  \n",
    "Graduate School of Arts and Sciences, https://gsas.harvard.edu  \n",
    "Not found  \n",
    "\n",
    "────────────────────────────────────────────────────────\n",
    "Pages to consult first:  \n",
    "• Admissions URL: {admissions_url}  \n",
    "• Program URL:    {program_url}\n",
    "\n",
    "What is the school/college and its homepage?\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "# Async Gemini wrapper\n",
    "from call_api import async_call_gemini\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Concurrency guard – avoid hitting rate-limits\n",
    "# ---------------------------------------------------------------------------\n",
    "semaphore = asyncio.Semaphore(4)            # max concurrent rows\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Per-row worker\n",
    "# ---------------------------------------------------------------------------\n",
    "async def process_row(row, prompt_template, num_vote: int, model_name: str):\n",
    "    \"\"\"\n",
    "    1. Format the prompt for this row\n",
    "    2. Launch `num_vote` Gemini calls in parallel\n",
    "    3. Capture BOTH normal answers *and* every possible error case\n",
    "    4. Return a serialisable record\n",
    "    \"\"\"\n",
    "    async with semaphore:\n",
    "        row    = row.to_dict()\n",
    "        prompt = prompt_template.format(\n",
    "            university     = row[\"大学英文名称\"],\n",
    "            degree         = row[\"学位\"],\n",
    "            program        = row[\"专业英文名称\"],\n",
    "            department     = row[\"所属院系\"],\n",
    "            admissions_url = row[\"招生网址\"],\n",
    "            program_url    = row[\"专业网址\"],\n",
    "        )\n",
    "\n",
    "        record: dict = row.copy()\n",
    "        record[\"llm_reponses\"] = {}\n",
    "\n",
    "        # -------- launch Gemini calls in parallel --------------------\n",
    "        tasks = [\n",
    "            async_call_gemini(\n",
    "                prompt,\n",
    "                model_name=model_name,\n",
    "                use_search=True,\n",
    "                url_context=True\n",
    "            )\n",
    "            for _ in range(num_vote)\n",
    "        ]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "\n",
    "        # -------- post-process each response -------------------------\n",
    "        for i, response in enumerate(responses):\n",
    "            resp_key = f\"response {i+1}\"\n",
    "\n",
    "            # -- 1. Transport / server-side errors (string starting \"Error:\")\n",
    "            if isinstance(response, str) and response.startswith(\"Error:\"):\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": response                       # e.g. \"Error: 429 Rate limit …\"\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 2. Empty / malformed response objects\n",
    "            if not hasattr(response, \"candidates\") or not response.candidates:\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": \"No candidates returned\",\n",
    "                    \"raw_response\": str(response)\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 3. Extract main answer text\n",
    "            try:\n",
    "                text = response.candidates[0].content.parts[0].text\n",
    "            except Exception as e:\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": f\"Cannot parse text: {e}\",\n",
    "                    \"raw_response\": str(response)\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 4. Extract additional metadata (best-effort)\n",
    "            try:\n",
    "                url_context = str(response.candidates[0].url_context_metadata)\n",
    "            except Exception:\n",
    "                url_context = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_pages = (\n",
    "                    f\"Search Chunks: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.grounding_chunks}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_pages = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_queries = (\n",
    "                    f\"Search Query: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.web_search_queries}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_queries = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_support = (\n",
    "                    f\"Search Supports: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.groundingSupports}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_support = \"Not used\"\n",
    "\n",
    "            # -- 5. Store normal answer + metadata + raw object\n",
    "            record[\"llm_reponses\"][resp_key] = {\n",
    "                \"response_text\": text,\n",
    "                \"url_context\": url_context,\n",
    "                \"search_queries\": search_queries,\n",
    "                \"search_pages\": search_pages,\n",
    "                \"search_support\": search_support,\n",
    "                \"raw_response\": str(response)             # keep for deep-debugging\n",
    "            }\n",
    "\n",
    "        return record\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Batch orchestrator with tqdm progress bar\n",
    "# ---------------------------------------------------------------------------\n",
    "async def request_and_store_async(prompt_template,\n",
    "                                  field_df,\n",
    "                                  num_vote: int,\n",
    "                                  model_name: str,\n",
    "                                  start_from: int = 0,\n",
    "                                  end_at: int = -1):\n",
    "    \"\"\"\n",
    "    Runs `process_row` over the dataframe slice asynchronously,\n",
    "    shows a live tqdm bar, and dumps the results to JSON.\n",
    "    \"\"\"\n",
    "    df = field_df.copy()[start_from:end_at]\n",
    "\n",
    "    # Spawn tasks for every row in the slice\n",
    "    tasks = [\n",
    "        process_row(row, prompt_template, num_vote, model_name)\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # tqdm_asyncio.gather gives us progress updates as tasks complete\n",
    "    response_records = await tqdm_asyncio.gather(*tasks)\n",
    "\n",
    "    # Persist to disk ------------------------------------------------\n",
    "    output_dir = f\"../fields_records/{field_name}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = f\"{output_dir}/{field_name}_{model_name}_{start_from}_{end_at}.json\"\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(response_records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return response_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [26:08<00:00,  4.48s/it]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Only needed in Jupyter\n",
    "\n",
    "num_vote = 3\n",
    "start_from = 0\n",
    "end_at = -1\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "response_records = asyncio.run(\n",
    "    request_and_store_async(prompt_template, field_df, num_vote, model_name, start_from=start_from, end_at=end_at)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def extract_department_from_json(json_file_path, output_csv_path):\n",
    "    \"\"\"\n",
    "    从JSON文件中提取所属院系（英文）信息\n",
    "    \n",
    "    Args:\n",
    "        json_file_path: JSON文件路径\n",
    "        output_csv_path: 输出CSV文件路径\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: 处理后的数据\n",
    "    \"\"\"\n",
    "    \n",
    "    # 读取JSON文件\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for record in data:\n",
    "        # 提取基本信息\n",
    "        basic_info = {\n",
    "            '大学英文名称': record.get('大学英文名称', ''),\n",
    "            '学位': record.get('学位', ''),\n",
    "            '专业英文名称': record.get('专业英文名称', ''),\n",
    "            '所属院系': record.get('所属院系', ''),\n",
    "            '招生网址': record.get('招生网址', ''),\n",
    "            '专业网址': record.get('专业网址', ''),\n",
    "        }\n",
    "        \n",
    "        # 提取LLM响应\n",
    "        llm_responses = record.get('llm_reponses', {})\n",
    "        \n",
    "        # 提取三次回答的response_text\n",
    "        response_texts = []\n",
    "        for i in range(1, 4):\n",
    "            response_key = f\"response {i}\"\n",
    "            if response_key in llm_responses:\n",
    "                response_text = llm_responses[response_key].get('response_text', '')\n",
    "                response_texts.append(response_text)\n",
    "            else:\n",
    "                response_texts.append('')\n",
    "        \n",
    "        # 比较三个回答的一致性并选择最终答案\n",
    "        selected_response, consistency_info, valid_responses = select_best_response(response_texts)\n",
    "        \n",
    "        # 解析选中的回答，提取院系名称和URL\n",
    "        department_name, department_url = parse_response_text(selected_response)\n",
    "        \n",
    "        # 构建最终记录\n",
    "        final_record = basic_info.copy()\n",
    "        final_record.update({\n",
    "            '所属院系（英文）': department_name,\n",
    "            '所属院系网址': department_url,\n",
    "            'response_1': response_texts[0] if len(response_texts) > 0 else '',\n",
    "            'response_2': response_texts[1] if len(response_texts) > 1 else '',\n",
    "            'response_3': response_texts[2] if len(response_texts) > 2 else '',\n",
    "            'response_1_valid': is_valid_response(response_texts[0]) if len(response_texts) > 0 else False,\n",
    "            'response_2_valid': is_valid_response(response_texts[1]) if len(response_texts) > 1 else False,\n",
    "            'response_3_valid': is_valid_response(response_texts[2]) if len(response_texts) > 2 else False,\n",
    "            'valid_response_count': len(valid_responses),\n",
    "            'consistency_type': consistency_info['type'],\n",
    "            'consistency_detail': consistency_info['detail']\n",
    "        })\n",
    "        \n",
    "        results.append(final_record)\n",
    "    \n",
    "    # 转换为DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # 重新排列列的顺序，确保重要信息在前面\n",
    "    column_order = [\n",
    "        '大学英文名称', '学位', '专业英文名称', '所属院系', \n",
    "        '所属院系（英文）', '所属院系网址',\n",
    "        '招生网址', '专业网址',\n",
    "        'valid_response_count', 'consistency_type', 'consistency_detail',\n",
    "        'response_1', 'response_1_valid',\n",
    "        'response_2', 'response_2_valid', \n",
    "        'response_3', 'response_3_valid'\n",
    "    ]\n",
    "    \n",
    "    # 确保所有列都存在\n",
    "    for col in column_order:\n",
    "        if col not in df.columns:\n",
    "            df[col] = ''\n",
    "    \n",
    "    # 按指定顺序重排列\n",
    "    df = df[column_order]\n",
    "    \n",
    "    # 保存为CSV\n",
    "    df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # 打印统计信息\n",
    "    print(f\"数据处理完成！\")\n",
    "    print(f\"总共处理了 {len(df)} 条记录\")\n",
    "    print(f\"有效回答统计:\")\n",
    "    valid_counts = df['valid_response_count'].value_counts().sort_index()\n",
    "    for count, records in valid_counts.items():\n",
    "        print(f\"  {count}个有效回答: {records} 条记录\")\n",
    "    print(f\"一致性统计:\")\n",
    "    consistency_counts = df['consistency_type'].value_counts()\n",
    "    for consistency_type, count in consistency_counts.items():\n",
    "        print(f\"  {consistency_type}: {count} 条\")\n",
    "    \n",
    "    # 统计成功提取的院系信息\n",
    "    successful_extractions = len(df[df['所属院系（英文）'] != ''])\n",
    "    print(f\"成功提取院系信息: {successful_extractions}/{len(df)} ({successful_extractions/len(df):.1%})\")\n",
    "    \n",
    "    print(f\"数据已保存到: {output_csv_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def is_valid_response(response_text):\n",
    "    \"\"\"\n",
    "    检查回答是否符合\"school, url\"格式\n",
    "    \n",
    "    Args:\n",
    "        response_text: LLM的回答文本\n",
    "    \n",
    "    Returns:\n",
    "        bool: 是否为合法格式\n",
    "    \"\"\"\n",
    "    \n",
    "    if not response_text or not response_text.strip():\n",
    "        return False\n",
    "    \n",
    "    # 去除首尾空白\n",
    "    text = response_text.strip()\n",
    "    \n",
    "    # 检查是否包含逗号\n",
    "    if ',' not in text:\n",
    "        return False\n",
    "    \n",
    "    # 检查长度（过长的回答通常是解释性文本）\n",
    "    if len(text) > 200:  # 设置最大长度限制\n",
    "        return False\n",
    "    \n",
    "    # 检查是否包含URL\n",
    "    url_pattern = r'https?://[^\\s,]+'\n",
    "    if not re.search(url_pattern, text):\n",
    "        return False\n",
    "    \n",
    "    # 检查是否包含某些无效关键词\n",
    "    invalid_keywords = [\n",
    "        'not found', 'not available', 'unable to find', 'could not find',\n",
    "        'no information', 'not mentioned', 'unclear', 'not specified',\n",
    "        'the browse results', 'clearly indicate', 'according to'\n",
    "    ]\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    for keyword in invalid_keywords:\n",
    "        if keyword in text_lower:\n",
    "            return False\n",
    "    \n",
    "    # 分割并检查格式\n",
    "    parts = text.split(',')\n",
    "    if len(parts) < 2:\n",
    "        return False\n",
    "    \n",
    "    # 第一部分应该是学院名称（不应该太短或包含特殊词汇）\n",
    "    school_part = parts[0].strip()\n",
    "    if len(school_part) < 5:  # 学院名称不应该太短\n",
    "        return False\n",
    "    \n",
    "    # 第二部分应该包含URL\n",
    "    url_part = ','.join(parts[1:]).strip()\n",
    "    if not re.search(url_pattern, url_part):\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def select_best_response(response_texts):\n",
    "    \"\"\"\n",
    "    根据一致性选择最佳回答（只考虑合法格式的回答）\n",
    "    \n",
    "    Args:\n",
    "        response_texts: 三个LLM回答的列表\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (选中的回答, 一致性信息, 有效回答列表)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 过滤出符合格式的有效回答\n",
    "    valid_responses = [resp for resp in response_texts if is_valid_response(resp)]\n",
    "    \n",
    "    if not valid_responses:\n",
    "        return '', {'type': 'no_valid_response', 'detail': 'No valid responses found'}, []\n",
    "    \n",
    "    if len(valid_responses) == 1:\n",
    "        return valid_responses[0], {'type': 'single_valid_response', 'detail': 'Only one valid response'}, valid_responses\n",
    "    \n",
    "    # 统计每个有效回答出现的次数\n",
    "    response_counts = Counter(valid_responses)\n",
    "    most_common = response_counts.most_common()\n",
    "    \n",
    "    # 完全一致（所有有效回答都相同）\n",
    "    if len(most_common) == 1:\n",
    "        return most_common[0][0], {'type': 'all_valid_same', 'detail': f'All {most_common[0][1]} valid responses are identical'}, valid_responses\n",
    "    \n",
    "    # 两个或更多相同，选择出现次数最多的\n",
    "    if most_common[0][1] >= 2:\n",
    "        return most_common[0][0], {'type': 'majority_valid_same', 'detail': f'{most_common[0][1]} valid responses are identical'}, valid_responses\n",
    "    \n",
    "    # 所有有效回答都不同，随机选择一个\n",
    "    selected = random.choice(valid_responses)\n",
    "    return selected, {'type': 'all_valid_different', 'detail': 'All valid responses are different, randomly selected'}, valid_responses\n",
    "\n",
    "def parse_response_text(response_text):\n",
    "    \"\"\"\n",
    "    解析回答文本，提取院系名称和URL\n",
    "    \n",
    "    Args:\n",
    "        response_text: LLM的回答文本\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (院系名称, URL)\n",
    "    \"\"\"\n",
    "    \n",
    "    if not response_text.strip():\n",
    "        return '', ''\n",
    "    \n",
    "    # 按逗号分割\n",
    "    parts = response_text.split(',')\n",
    "    \n",
    "    if len(parts) >= 2:\n",
    "        department_name = parts[0].strip()\n",
    "        \n",
    "        # 在第二部分及之后寻找URL\n",
    "        url_part = ','.join(parts[1:]).strip()\n",
    "        \n",
    "        # 提取URL\n",
    "        url_pattern = r'https?://[^\\s,]+'\n",
    "        url_match = re.search(url_pattern, url_part)\n",
    "        \n",
    "        if url_match:\n",
    "            department_url = url_match.group()\n",
    "            # 清理URL末尾的标点符号\n",
    "            department_url = re.sub(r'[,\\.\\s]+$', '', department_url)\n",
    "        else:\n",
    "            department_url = ''\n",
    "    \n",
    "    else:\n",
    "        # 如果没有逗号，整个文本作为院系名称\n",
    "        department_name = response_text.strip()\n",
    "        department_url = ''\n",
    "    \n",
    "    return department_name, department_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据处理完成！\n",
      "总共处理了 350 条记录\n",
      "有效回答统计:\n",
      "  0个有效回答: 3 条记录\n",
      "  1个有效回答: 18 条记录\n",
      "  2个有效回答: 74 条记录\n",
      "  3个有效回答: 255 条记录\n",
      "一致性统计:\n",
      "  all_valid_same: 144 条\n",
      "  majority_valid_same: 110 条\n",
      "  all_valid_different: 75 条\n",
      "  single_valid_response: 18 条\n",
      "  no_valid_response: 3 条\n",
      "成功提取院系信息: 347/350 (99.1%)\n",
      "数据已保存到: 所属院系英文_处理结果.csv\n",
      "\n",
      "前5条记录预览：\n",
      "                大学英文名称                       专业英文名称  \\\n",
      "0   Harvard University            Data Science SEAS   \n",
      "1   Harvard University                 Data Science   \n",
      "2  Stanford University                 Data Science   \n",
      "3  Stanford University                 Data Science   \n",
      "4      Yale University  Statistics and Data Science   \n",
      "\n",
      "                                            所属院系（英文）  \\\n",
      "0  Harvard John A. Paulson School of Engineering ...   \n",
      "1                           Harvard Extension School   \n",
      "2                              School of Engineering   \n",
      "3                  School of Humanities and Sciences   \n",
      "4               Graduate School of Arts and Sciences   \n",
      "\n",
      "                             所属院系网址  valid_response_count     consistency_type  \n",
      "0          https://seas.harvard.edu                     3       all_valid_same  \n",
      "1     https://extension.harvard.edu                     3       all_valid_same  \n",
      "2  https://engineering.stanford.edu                     3  majority_valid_same  \n",
      "3      https://humsci.stanford.edu/                     3  majority_valid_same  \n",
      "4             https://gsas.yale.edu                     3       all_valid_same  \n",
      "\n",
      "=== 成功提取院系信息的示例 ===\n",
      "大学: Harvard University\n",
      "专业: Data Science SEAS\n",
      "原始院系: 约翰·保尔森工程与应用科学学院\n",
      "英文院系: Harvard John A. Paulson School of Engineering and Applied Sciences\n",
      "院系网址: https://seas.harvard.edu\n",
      "有效回答数: 3\n",
      "一致性: all_valid_same\n",
      "--------------------------------------------------\n",
      "大学: Harvard University\n",
      "专业: Data Science\n",
      "原始院系: Harvard Extension School\n",
      "英文院系: Harvard Extension School\n",
      "院系网址: https://extension.harvard.edu\n",
      "有效回答数: 3\n",
      "一致性: all_valid_same\n",
      "--------------------------------------------------\n",
      "大学: Stanford University\n",
      "专业: Data Science\n",
      "原始院系: 工程学院\n",
      "英文院系: School of Engineering\n",
      "院系网址: https://engineering.stanford.edu\n",
      "有效回答数: 3\n",
      "一致性: majority_valid_same\n",
      "--------------------------------------------------\n",
      "大学: Stanford University\n",
      "专业: Data Science\n",
      "原始院系: 人文科学学院\n",
      "英文院系: School of Humanities and Sciences\n",
      "院系网址: https://humsci.stanford.edu/\n",
      "有效回答数: 3\n",
      "一致性: majority_valid_same\n",
      "--------------------------------------------------\n",
      "大学: Yale University\n",
      "专业: Statistics and Data Science\n",
      "原始院系: 艺术与科学研究生院\n",
      "英文院系: Graduate School of Arts and Sciences\n",
      "院系网址: https://gsas.yale.edu\n",
      "有效回答数: 3\n",
      "一致性: all_valid_same\n",
      "--------------------------------------------------\n",
      "\n",
      "=== 未能提取院系信息的示例 ===\n",
      "大学: Binghamton University, SUNY\n",
      "专业: Data Analytics (MS)\n",
      "原始院系: 研究生跨学科项目\n",
      "回答1: The program is a \"collaborative\" effort of three schools: Harpur College of Arts and Sciences, School of Management, and Thomas J. Watson College of Engineering and Applied Science.\n",
      "The prompt asks for *one* clear school/college name and its most authoritative homepage URL. Since the program is a collaboration, it doesn't clearly \"house\" in one specific school. However, the \"Thomas J. Watson College of Engineering and Applied Science\" sounds like a strong candidate, given the nature of a Data Analytics MS, and \"engineering\" often implies a more technical, applied science focus. I will check the homepage of each of the three schools mentioned to see if one of them is the primary home or if there's a dedicated graduate school for such programs.\n",
      "\n",
      "I will start by searching for the \"Thomas J. Watson College of Engineering and Applied Science Binghamton University\" homepage. Then, if needed, I will check the other two.\n",
      "\n",
      "Let's try to search specifically for \"Thomas J. Watson College of Engineering and Applied Science Binghamton University site:.edu\" and other two colleges. (有效: False)\n",
      "回答2: The program description states: \"The STEM program leverages the cross-disciplinary insights of three of Binghamton University's schools: Harpur College of Arts and Sciences, School of Management, Thomas J. Watson College of Engineering and Applied Science.\"\n",
      "\n",
      "This indicates that the program is not housed within a single school but is a collaboration. However, the user explicitly asks for \"one clear school/college name\" and \"the most authoritative homepage URL for *that school*\". Since it's a collaborative program, finding a single school that \"houses\" it might be tricky.\n",
      "\n",
      "Given the options, the program is housed within three schools. I need to choose the most appropriate one or state \"Not found\" if no single school is identified as the primary housing entity.\n",
      "\n",
      "Let's check if the program has a primary affiliation with one of these schools or if there's a dedicated graduate school that oversees it. The admissions page mentions \"The Graduate School website\" for more information about graduate study at Binghamton University. This is a good lead.\n",
      "\n",
      "I will browse the Graduate School website to see if it acts as the primary administrative body for this program or if it offers a more general overview.\n",
      " (有效: False)\n",
      "回答3: Not found (有效: False)\n",
      "原因: No valid responses found\n",
      "--------------------------------------------------\n",
      "大学: Worcester Polytechnic Institute\n",
      "专业: DATA SCIENCE\n",
      "原始院系: 文理学院\n",
      "回答1:  (有效: False)\n",
      "回答2: Not found (有效: False)\n",
      "回答3: Not found (有效: False)\n",
      "原因: No valid responses found\n",
      "--------------------------------------------------\n",
      "大学: Worcester Polytechnic Institute\n",
      "专业: DATA SCIENCE\n",
      "原始院系: 文理学院\n",
      "回答1:  (有效: False)\n",
      "回答2: Not found (有效: False)\n",
      "回答3: Not found (有效: False)\n",
      "原因: No valid responses found\n",
      "--------------------------------------------------\n",
      "\n",
      "=== 数据完整性检查 ===\n",
      "有院系名称的记录: 347/350\n",
      "有院系网址的记录: 347/350\n",
      "同时有名称和网址的记录: 347/350\n"
     ]
    }
   ],
   "source": [
    "json_file = \"/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/DataScience/fields_records/所属院系（英文）/所属院系（英文）_gemini-2.5-flash_0_-1.json\"\n",
    "output_csv = \"所属院系英文_处理结果.csv\"\n",
    "\n",
    "df = extract_department_from_json(json_file, output_csv)\n",
    "\n",
    "# 显示前几条记录\n",
    "print(\"\\n前5条记录预览：\")\n",
    "display_columns = ['大学英文名称', '专业英文名称', '所属院系（英文）', '所属院系网址', 'valid_response_count', 'consistency_type']\n",
    "print(df[display_columns].head())\n",
    "\n",
    "# 显示成功提取的示例\n",
    "print(f\"\\n=== 成功提取院系信息的示例 ===\")\n",
    "successful = df[df['所属院系（英文）'] != ''].head(5)\n",
    "for _, row in successful.iterrows():\n",
    "    print(f\"大学: {row['大学英文名称']}\")\n",
    "    print(f\"专业: {row['专业英文名称']}\")\n",
    "    print(f\"原始院系: {row['所属院系']}\")\n",
    "    print(f\"英文院系: {row['所属院系（英文）']}\")\n",
    "    print(f\"院系网址: {row['所属院系网址']}\")\n",
    "    print(f\"有效回答数: {row['valid_response_count']}\")\n",
    "    print(f\"一致性: {row['consistency_type']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 显示失败的示例\n",
    "print(f\"\\n=== 未能提取院系信息的示例 ===\")\n",
    "failed = df[df['所属院系（英文）'] == ''].head(3)\n",
    "for _, row in failed.iterrows():\n",
    "    print(f\"大学: {row['大学英文名称']}\")\n",
    "    print(f\"专业: {row['专业英文名称']}\")\n",
    "    print(f\"原始院系: {row['所属院系']}\")\n",
    "    print(f\"回答1: {row['response_1']} (有效: {row['response_1_valid']})\")\n",
    "    print(f\"回答2: {row['response_2']} (有效: {row['response_2_valid']})\")\n",
    "    print(f\"回答3: {row['response_3']} (有效: {row['response_3_valid']})\")\n",
    "    print(f\"原因: {row['consistency_detail']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 验证数据完整性\n",
    "print(f\"\\n=== 数据完整性检查 ===\")\n",
    "has_department_name = len(df[df['所属院系（英文）'] != ''])\n",
    "has_department_url = len(df[df['所属院系网址'] != ''])\n",
    "has_both = len(df[(df['所属院系（英文）'] != '') & (df['所属院系网址'] != '')])\n",
    "\n",
    "print(f\"有院系名称的记录: {has_department_name}/{len(df)}\")\n",
    "print(f\"有院系网址的记录: {has_department_url}/{len(df)}\")\n",
    "print(f\"同时有名称和网址的记录: {has_both}/{len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
