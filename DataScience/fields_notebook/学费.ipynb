{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 9)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/Users/yijingyang/Library/CloudStorage/OneDrive-ä¸ªäºº/GradPilot/ProgramDB/DataScience')\n",
    "import asyncio\n",
    "from call_api import call_gemini, async_call_gemini\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "field_name = \"å­¦è´¹\"\n",
    "field_path = f\"/Users/yijingyang/Library/CloudStorage/OneDrive-ä¸ªäºº/GradPilot/ProgramDB/DataScience/fields_csv/{field_name}.csv\"\n",
    "field_df = pd.read_csv(field_path)\n",
    "\n",
    "field_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an assistant whose sole task is to extract the **official tuition cost** for the graduate program below.\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ğŸ’¡  How to find the tuition:\n",
    "\n",
    "1. **Read only primary sources**  \n",
    "   â€¢ Admissions URL and Program URL provided below.  \n",
    "   â€¢ Any page within the universityâ€™s *.edu* domain.  \n",
    "   â›” Ignore blogs, news sites, rankings, PDF aggregators, or any non-*.edu* domain.\n",
    "\n",
    "2. **Search guideline**  \n",
    "   Use Google with the exact query:  \n",
    "   \"{university} {school} {degree} {program} tuition fee site:.edu\"  \n",
    "   Open results until you reach an authoritative tuition page (e.g., â€œTuition & Feesâ€, â€œCost of Attendanceâ€, Bursar).\n",
    "\n",
    "3. **Pick the most specific figure**  \n",
    "   â€¢ Prefer program-specific tuition; if unavailable, use the generic graduate rate for that school/college.  \n",
    "   â€¢ If multiple billing units exist, choose this priority:  \n",
    "     (a) **Per academic year (full-time)**  \n",
    "     (b) Per semester / quarter (full-time)  \n",
    "     (c) Per credit hour (specify â€œper creditâ€)  \n",
    "   â€¢ Do **not** do any arithmetic or conversionsâ€”quote the number exactly as written (include currency symbol and billing unit).\n",
    "\n",
    "4. **Handle ambiguity**  \n",
    "   â€¢ If the page lists several tracks (e.g., online vs on-campus) choose the **on-campus** rate unless the program is explicitly online-only.  \n",
    "   â€¢ If tuition is shown as a range, return the **lower bound** followed by â€œ+â€ (e.g., â€œ$21,000+ per semesterâ€).  \n",
    "   â€¢ If you cannot find a trustworthy *.edu* source or numbers conflict, output **â€œNot foundâ€**.\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "âš ï¸  **Output format (one line only, no quotes, no extra text)**  \n",
    "â€¢ Either:  $21,432 per academic year  \n",
    "â€¢ Or:     Not found\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Pages to consult first:\n",
    "â€¢ Admissions URL: {admissions_url}  \n",
    "â€¢ Program URL:    {program_url}\n",
    "\n",
    "What is the tuition for this program?\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "semaphore = asyncio.Semaphore(3) \n",
    "\n",
    "async def process_row(row, prompt_template, num_vote, model_name):\n",
    "    async with semaphore:\n",
    "        row = row.to_dict()\n",
    "        prompt = prompt_template.format(\n",
    "            university     = row[\"å¤§å­¦è‹±æ–‡åç§°\"],\n",
    "            degree         = row[\"å­¦ä½\"],\n",
    "            school         = row[\"æ‰€å±é™¢ç³»ï¼ˆè‹±æ–‡ï¼‰\"],\n",
    "            program        = row[\"ä¸“ä¸šè‹±æ–‡åç§°\"],\n",
    "            department     = row[\"æ‰€å±é™¢ç³»\"],\n",
    "            admissions_url = row[\"æ‹›ç”Ÿç½‘å€\"],\n",
    "            program_url    = row[\"ä¸“ä¸šç½‘å€\"],\n",
    "        )\n",
    "        record = row.copy()\n",
    "        record[\"llm_reponses\"] = {}\n",
    "\n",
    "        # Launch all API calls in parallel for this row\n",
    "        tasks = [\n",
    "            async_call_gemini(prompt, model_name=model_name, use_search=True, url_context=True)\n",
    "            for _ in range(num_vote)\n",
    "        ]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "\n",
    "        for i, response in enumerate(responses):\n",
    "            try:\n",
    "                text = response.candidates[0].content.parts[0].text\n",
    "            except:\n",
    "                text = ''\n",
    "            try:\n",
    "                url_context = str(response.candidates[0].url_context_metadata)\n",
    "            except:\n",
    "                url_context = \"Not used\"\n",
    "            try:\n",
    "                search_pages = f\"Search Chunks: {response.candidates[0].grounding_metadata.grounding_chunks}\"\n",
    "            except:\n",
    "                search_pages = \"Not used\"\n",
    "            try:\n",
    "                search_queries = f\"Search Query: {response.candidates[0].grounding_metadata.web_search_queries}\"\n",
    "            except:\n",
    "                search_queries = \"Not used\"\n",
    "            try:\n",
    "                search_support = f\"Search Query: {response.candidates[0].grounding_metadata.groundingSupports}\"\n",
    "            except:\n",
    "                search_support = \"Not used\"\n",
    "\n",
    "            record[\"llm_reponses\"][f\"response {i+1}\"] = {\n",
    "                \"response_text\": text,\n",
    "                \"url_context\": url_context,\n",
    "                \"search_queries\": search_queries,\n",
    "                \"search_pages\": search_pages,\n",
    "                \"search_support\": search_support,\n",
    "            }\n",
    "        return record\n",
    "\n",
    "async def request_and_store_async(prompt_template, field_df, num_vote, model_name, start_from=0, end_at=-1):\n",
    "    df = field_df.copy()[start_from:end_at]\n",
    "    response_records = []\n",
    "\n",
    "    # Create tasks for all rows\n",
    "    tasks = [\n",
    "        process_row(row, prompt_template, num_vote, model_name)\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "    # Run all row tasks in parallel (limit concurrency if needed)\n",
    "    response_records = await tqdm_asyncio.gather(*tasks)\n",
    "\n",
    "    # Save results\n",
    "    with open(f\"../fields_records/{field_name}/{field_name}_{model_name}_{start_from}_{end_at}.json\", \"w\") as f:\n",
    "        json.dump(response_records, f, ensure_ascii=False, indent=2)\n",
    "    return response_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [03:26<00:00, 10.34s/it]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Only needed in Jupyter\n",
    "\n",
    "num_vote = 3\n",
    "start_from = 30\n",
    "end_at = 50\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "response_records = asyncio.run(\n",
    "    request_and_store_async(prompt_template, field_df, num_vote, model_name, start_from=start_from, end_at=end_at)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(records):\n",
    "    for rec in records:\n",
    "        responses = rec[\"llm_reponses\"]\n",
    "        candidate_answers = [r for r in responses.values() if \"no explicit constraints\" not in r]\n",
    "        if len(candidate_answers) > 0:\n",
    "            rec[\"åŒç”³äº’æ–¥\"] = candidate_answers[0]\n",
    "        else:\n",
    "            rec[\"åŒç”³äº’æ–¥\"] = \"no explicit constraints\"\n",
    "    return records\n",
    "num_vote = 3\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "field_name = \"åŒç”³äº’æ–¥\"\n",
    "accuracy = \"median_accuracy\"\n",
    "with open(f\"../fields_records/{field_name}_{model_name}_0_-1.json\", \"r\") as f:\n",
    "    records = json.load(f)\n",
    "records = majority_vote(records)\n",
    "with open(f\"../fields_records/{field_name}_{model_name}_{accuracy}.json\", \"w\") as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
