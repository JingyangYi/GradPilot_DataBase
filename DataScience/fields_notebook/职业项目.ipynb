{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/DataScience')\n",
    "import asyncio\n",
    "from call_api import call_gemini, async_call_gemini\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "field_name = \"职业项目\"\n",
    "field_path = f\"/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/DataScience/fields_csv/{field_name}.csv\"\n",
    "field_df = pd.read_csv(field_path)\n",
    "\n",
    "field_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an assistant who must classify the graduate program below as either **“professional”** (career-focused) or **“non-professional”** (academic / research-oriented).\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────\n",
    "📌  What defines a *professional* program?\n",
    "• **Skill-centric curriculum** – Courses concentrate on concrete industry tools and competencies (e.g., product management, data visualization, enterprise risk, UX design).  \n",
    "• **Limited research emphasis** – Little or no mention of faculty-led research labs, theses, or publications; instead you see capstones, practicums, or internships.  \n",
    "• **Flexible delivery** – Frequently online or hybrid, offered evenings/weekends, with multiple or rolling start dates (not just Fall) and variable part-time / full-time durations (≈ 9-24 months).  \n",
    "• **Career-first language** – Website text highlights phrases like “advance your career,” “taught by industry experts,” “immediate ROI,” “professional network,” “salary growth,” etc.\n",
    "\n",
    "🔍  Example programs (for context; do **not** classify these):\n",
    "1. Columbia University – M.S. Enterprise Risk Management (School of Professional Studies)  \n",
    "2. Harvard Extension School – A.L.M. in Management  \n",
    "3. NYU School of Professional Studies – M.S. Integrated Marketing  \n",
    "4. Johns Hopkins Engineering for Professionals – M.S. Cybersecurity  \n",
    "\n",
    "Unless the website clearly meets the criteria above, label the program **non-professional**.  \n",
    "────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "⚠️  **Output format**  \n",
    "Return **exactly one line**: either  \n",
    "``professional``  \n",
    "or  \n",
    "``non-professional``  \n",
    "No additional words, punctuation, or explanations.\n",
    "\n",
    "Links to consult:  \n",
    "• Admissions URL: {admissions_url}  \n",
    "• Program URL: {program_url}\n",
    "\n",
    "Is this program a professional program?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "# Async Gemini wrapper\n",
    "from call_api import async_call_gemini\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Concurrency guard – avoid hitting rate-limits\n",
    "# ---------------------------------------------------------------------------\n",
    "semaphore = asyncio.Semaphore(2)            # max concurrent rows\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Per-row worker\n",
    "# ---------------------------------------------------------------------------\n",
    "async def process_row(row, prompt_template, num_vote: int, model_name: str):\n",
    "    \"\"\"\n",
    "    1. Format the prompt for this row\n",
    "    2. Launch `num_vote` Gemini calls in parallel\n",
    "    3. Capture BOTH normal answers *and* every possible error case\n",
    "    4. Return a serialisable record\n",
    "    \"\"\"\n",
    "    async with semaphore:\n",
    "        row    = row.to_dict()\n",
    "        prompt = prompt_template.format(\n",
    "            university     = row[\"大学英文名称\"],\n",
    "            degree         = row[\"学位\"],\n",
    "            program        = row[\"专业英文名称\"],\n",
    "            department     = row[\"所属院系\"],\n",
    "            admissions_url = row[\"招生网址\"],\n",
    "            program_url    = row[\"专业网址\"],\n",
    "        )\n",
    "\n",
    "        record: dict = row.copy()\n",
    "        record[\"llm_reponses\"] = {}\n",
    "\n",
    "        # -------- launch Gemini calls in parallel --------------------\n",
    "        tasks = [\n",
    "            async_call_gemini(\n",
    "                prompt,\n",
    "                model_name=model_name,\n",
    "                use_search=True,\n",
    "                url_context=True\n",
    "            )\n",
    "            for _ in range(num_vote)\n",
    "        ]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "\n",
    "        # -------- post-process each response -------------------------\n",
    "        for i, response in enumerate(responses):\n",
    "            resp_key = f\"response {i+1}\"\n",
    "\n",
    "            # -- 1. Transport / server-side errors (string starting \"Error:\")\n",
    "            if isinstance(response, str) and response.startswith(\"Error:\"):\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": response                       # e.g. \"Error: 429 Rate limit …\"\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 2. Empty / malformed response objects\n",
    "            if not hasattr(response, \"candidates\") or not response.candidates:\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": \"No candidates returned\",\n",
    "                    \"raw_response\": str(response)\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 3. Extract main answer text\n",
    "            try:\n",
    "                text = response.candidates[0].content.parts[0].text\n",
    "            except Exception as e:\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": f\"Cannot parse text: {e}\",\n",
    "                    \"raw_response\": str(response)\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 4. Extract additional metadata (best-effort)\n",
    "            try:\n",
    "                url_context = str(response.candidates[0].url_context_metadata)\n",
    "            except Exception:\n",
    "                url_context = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_pages = (\n",
    "                    f\"Search Chunks: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.grounding_chunks}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_pages = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_queries = (\n",
    "                    f\"Search Query: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.web_search_queries}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_queries = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_support = (\n",
    "                    f\"Search Supports: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.groundingSupports}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_support = \"Not used\"\n",
    "\n",
    "            # -- 5. Store normal answer + metadata + raw object\n",
    "            record[\"llm_reponses\"][resp_key] = {\n",
    "                \"response_text\": text,\n",
    "                \"url_context\": url_context,\n",
    "                \"search_queries\": search_queries,\n",
    "                \"search_pages\": search_pages,\n",
    "                \"search_support\": search_support,\n",
    "                \"raw_response\": str(response)             # keep for deep-debugging\n",
    "            }\n",
    "\n",
    "        return record\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Batch orchestrator with tqdm progress bar\n",
    "# ---------------------------------------------------------------------------\n",
    "async def request_and_store_async(prompt_template,\n",
    "                                  field_df,\n",
    "                                  num_vote: int,\n",
    "                                  model_name: str,\n",
    "                                  start_from: int = 0,\n",
    "                                  end_at: int = -1):\n",
    "    \"\"\"\n",
    "    Runs `process_row` over the dataframe slice asynchronously,\n",
    "    shows a live tqdm bar, and dumps the results to JSON.\n",
    "    \"\"\"\n",
    "    df = field_df.copy()[start_from:end_at]\n",
    "\n",
    "    # Spawn tasks for every row in the slice\n",
    "    tasks = [\n",
    "        process_row(row, prompt_template, num_vote, model_name)\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # tqdm_asyncio.gather gives us progress updates as tasks complete\n",
    "    response_records = await tqdm_asyncio.gather(*tasks)\n",
    "\n",
    "    # Persist to disk ------------------------------------------------\n",
    "    output_dir = f\"../fields_records/{field_name}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = f\"{output_dir}/{field_name}_{model_name}_{start_from}_{end_at}.json\"\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(response_records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return response_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [1:22:28<00:00, 14.14s/it]    \n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Only needed in Jupyter\n",
    "\n",
    "num_vote = 3\n",
    "start_from = 0\n",
    "end_at = -1\n",
    "model_name = \"gemini-2.5-pro\"\n",
    "response_records = asyncio.run(\n",
    "    request_and_store_async(prompt_template, field_df, num_vote, model_name, start_from=start_from, end_at=end_at)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取文件: /Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/DataScience/fields_records/职业项目/职业项目_gemini-2.5-pro_0_-1.json\n",
      "总项目数: 350\n",
      "发现无效回答: 361 个\n",
      "开始修复 361 个无效回答...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/361 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361/361 [43:14<00:00,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "修复完成!\n",
      "总回答数: 1050\n",
      "无效回答数: 361\n",
      "成功修复: 357\n",
      "修复失败: 4\n",
      "修复成功率: 98.9%\n",
      "\n",
      "重试统计:\n",
      "第1次尝试: 320 个回答\n",
      "第2次尝试: 33 个回答\n",
      "第3次尝试: 8 个回答\n",
      "\n",
      "修复后的文件已保存到: /Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/DataScience/fields_records/职业项目/职业项目_gemini-2.5-pro_0_-1_fixed.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import asyncio\n",
    "from call_api import async_call_gemini\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "async def fill_invalid_responses(json_file_path, prompt_template, validation_func, \n",
    "                                model_name=\"gemini-2.5-flash\", max_retries=2):\n",
    "    \"\"\"\n",
    "    检查JSON文件中的无效回答并重新请求，直到获得合法回答\n",
    "    \n",
    "    Args:\n",
    "        json_file_path (str): JSON文件路径\n",
    "        prompt_template (str): 提示词模板\n",
    "        validation_func (function): 验证函数，返回(is_valid, status)\n",
    "        model_name (str): 模型名称\n",
    "        max_retries (int): 最大重试次数\n",
    "    \n",
    "    Returns:\n",
    "        dict: 处理统计信息\n",
    "    \"\"\"\n",
    "    \n",
    "    def is_valid_professional_response(response_text):\n",
    "        \"\"\"验证职业项目分类回答是否合法\"\"\"\n",
    "        if not response_text or response_text.strip() == \"\":\n",
    "            return False, \"空白回答\"\n",
    "        \n",
    "        response_clean = response_text.strip().lower()\n",
    "        \n",
    "        if len(response_text) > 100:\n",
    "            return False, \"回答过长\"\n",
    "        \n",
    "        if response_clean in [\"professional\", \"non-professional\"]:\n",
    "            return True, \"有效回答\"\n",
    "        \n",
    "        return False, \"无效分类\"\n",
    "    \n",
    "    async def get_new_response(prompt):\n",
    "        \"\"\"获取新的回答\"\"\"\n",
    "        try:\n",
    "            response = await async_call_gemini(\n",
    "                prompt,\n",
    "                model_name=model_name,\n",
    "                use_search=True,\n",
    "                url_context=True\n",
    "            )\n",
    "            \n",
    "            # 处理错误响应\n",
    "            if isinstance(response, str) and response.startswith(\"Error:\"):\n",
    "                return None, f\"API错误: {response}\"\n",
    "            \n",
    "            # 处理空响应\n",
    "            if not hasattr(response, \"candidates\") or not response.candidates:\n",
    "                return None, \"无candidates\"\n",
    "            \n",
    "            # 提取回答文本\n",
    "            try:\n",
    "                text = response.candidates[0].content.parts[0].text\n",
    "                return text, \"成功获取\"\n",
    "            except Exception as e:\n",
    "                return None, f\"解析失败: {e}\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return None, f\"请求异常: {e}\"\n",
    "    \n",
    "    # 读取JSON文件\n",
    "    print(f\"读取文件: {json_file_path}\")\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(f\"总项目数: {len(data)}\")\n",
    "    \n",
    "    # 统计信息\n",
    "    stats = {\n",
    "        'total_projects': len(data),\n",
    "        'total_responses': 0,\n",
    "        'invalid_responses': 0,\n",
    "        'fixed_responses': 0,\n",
    "        'failed_fixes': 0,\n",
    "        'retry_stats': {}\n",
    "    }\n",
    "    \n",
    "    # 收集所有需要修复的项目\n",
    "    projects_to_fix = []\n",
    "    \n",
    "    for i, project in enumerate(data):\n",
    "        llm_responses = project.get('llm_reponses', {})\n",
    "        \n",
    "        for resp_key, resp_data in llm_responses.items():\n",
    "            stats['total_responses'] += 1\n",
    "            \n",
    "            # 检查是否存在response_text字段\n",
    "            if 'response_text' not in resp_data:\n",
    "                # 如果没有response_text，可能是错误响应，标记为需要修复\n",
    "                stats['invalid_responses'] += 1\n",
    "                projects_to_fix.append((i, resp_key, project))\n",
    "                continue\n",
    "            \n",
    "            # 验证回答有效性\n",
    "            response_text = resp_data.get('response_text', '')\n",
    "            is_valid, status = validation_func(response_text)\n",
    "            \n",
    "            if not is_valid:\n",
    "                stats['invalid_responses'] += 1\n",
    "                projects_to_fix.append((i, resp_key, project))\n",
    "    \n",
    "    print(f\"发现无效回答: {stats['invalid_responses']} 个\")\n",
    "    \n",
    "    if not projects_to_fix:\n",
    "        print(\"所有回答都是有效的，无需修复\")\n",
    "        return stats\n",
    "    \n",
    "    # 限制并发数\n",
    "    semaphore = asyncio.Semaphore(2)\n",
    "    \n",
    "    async def fix_single_response(project_index, resp_key, project):\n",
    "        \"\"\"修复单个回答\"\"\"\n",
    "        async with semaphore:\n",
    "            # 构建提示词\n",
    "            prompt = prompt_template.format(\n",
    "                university=project[\"大学英文名称\"],\n",
    "                degree=project[\"学位\"],\n",
    "                program=project[\"专业英文名称\"],\n",
    "                department=project[\"所属院系\"],\n",
    "                admissions_url=project[\"招生网址\"],\n",
    "                program_url=project[\"专业网址\"],\n",
    "            )\n",
    "            \n",
    "            for retry_count in range(1, max_retries + 2):  # +1 因为从1开始计数\n",
    "                new_text, status = await get_new_response(prompt)\n",
    "                \n",
    "                if new_text is None:\n",
    "                    if retry_count <= max_retries:\n",
    "                        await asyncio.sleep(1)  # 短暂延迟\n",
    "                        continue\n",
    "                    else:\n",
    "                        # 最终失败\n",
    "                        return project_index, resp_key, None, f\"修复失败: {status}\", retry_count\n",
    "                \n",
    "                # 验证新回答\n",
    "                is_valid, validation_status = validation_func(new_text)\n",
    "                \n",
    "                if is_valid:\n",
    "                    # 成功获得有效回答\n",
    "                    return project_index, resp_key, new_text, f\"修复成功(第{retry_count}次尝试)\", retry_count\n",
    "                else:\n",
    "                    if retry_count <= max_retries:\n",
    "                        await asyncio.sleep(1)\n",
    "                        continue\n",
    "                    else:\n",
    "                        # 重试次数用完但仍无效\n",
    "                        return project_index, resp_key, new_text, f\"修复失败: {validation_status}\", retry_count\n",
    "            \n",
    "            return project_index, resp_key, None, \"意外错误\", max_retries + 1\n",
    "    \n",
    "    # 并行修复所有无效回答\n",
    "    print(f\"开始修复 {len(projects_to_fix)} 个无效回答...\")\n",
    "    \n",
    "    tasks = [\n",
    "        fix_single_response(project_index, resp_key, project)\n",
    "        for project_index, resp_key, project in projects_to_fix\n",
    "    ]\n",
    "    \n",
    "    results = await tqdm_asyncio.gather(*tasks)\n",
    "    \n",
    "    # 更新数据和统计\n",
    "    for project_index, resp_key, new_text, status, retry_count in results:\n",
    "        # 更新重试统计\n",
    "        if retry_count not in stats['retry_stats']:\n",
    "            stats['retry_stats'][retry_count] = 0\n",
    "        stats['retry_stats'][retry_count] += 1\n",
    "        \n",
    "        if new_text is not None and \"修复成功\" in status:\n",
    "            # 更新原始数据\n",
    "            data[project_index]['llm_reponses'][resp_key]['response_text'] = new_text\n",
    "            data[project_index]['llm_reponses'][resp_key]['fix_status'] = status\n",
    "            data[project_index]['llm_reponses'][resp_key]['fix_attempts'] = retry_count\n",
    "            stats['fixed_responses'] += 1\n",
    "        else:\n",
    "            # 修复失败，标记状态\n",
    "            data[project_index]['llm_reponses'][resp_key]['fix_status'] = status\n",
    "            data[project_index]['llm_reponses'][resp_key]['fix_attempts'] = retry_count\n",
    "            stats['failed_fixes'] += 1\n",
    "    \n",
    "    # 保存修复后的文件\n",
    "    output_path = json_file_path.replace('.json', '_fixed.json')\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # 打印统计信息\n",
    "    print(f\"\\n修复完成!\")\n",
    "    print(f\"总回答数: {stats['total_responses']}\")\n",
    "    print(f\"无效回答数: {stats['invalid_responses']}\")\n",
    "    print(f\"成功修复: {stats['fixed_responses']}\")\n",
    "    print(f\"修复失败: {stats['failed_fixes']}\")\n",
    "    print(f\"修复成功率: {stats['fixed_responses']/stats['invalid_responses']*100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n重试统计:\")\n",
    "    for attempts, count in stats['retry_stats'].items():\n",
    "        print(f\"第{attempts}次尝试: {count} 个回答\")\n",
    "    \n",
    "    print(f\"\\n修复后的文件已保存到: {output_path}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# 使用示例 - 职业项目分类\n",
    "async def fix_professional_classification():\n",
    "    \"\"\"修复职业项目分类的无效回答\"\"\"\n",
    "    \n",
    "    def is_valid_professional_response(response_text):\n",
    "        \"\"\"验证职业项目分类回答是否合法\"\"\"\n",
    "        if not response_text or response_text.strip() == \"\":\n",
    "            return False, \"空白回答\"\n",
    "        \n",
    "        response_clean = response_text.strip().lower()\n",
    "        \n",
    "        if len(response_text) > 100:\n",
    "            return False, \"回答过长\"\n",
    "        \n",
    "        if response_clean in [\"professional\", \"non-professional\"]:\n",
    "            return True, \"有效回答\"\n",
    "        \n",
    "        return False, \"无效分类\"\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "You are an assistant who must classify the graduate program below as either **\"professional\"** (career-focused) or **\"non-professional\"** (academic / research-oriented).\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────\n",
    "📌  What defines a *professional* program?\n",
    "• **Skill-centric curriculum** – Courses concentrate on concrete industry tools and competencies (e.g., product management, data visualization, enterprise risk, UX design).  \n",
    "• **Limited research emphasis** – Little or no mention of faculty-led research labs, theses, or publications; instead you see capstones, practicums, or internships.  \n",
    "• **Flexible delivery** – Frequently online or hybrid, offered evenings/weekends, with multiple or rolling start dates (not just Fall) and variable part-time / full-time durations (≈ 9-24 months).  \n",
    "• **Career-first language** – Website text highlights phrases like \"advance your career,\" \"taught by industry experts,\" \"immediate ROI,\" \"professional network,\" \"salary growth,\" etc.\n",
    "\n",
    "🔍  Example programs (for context; do **not** classify these):\n",
    "1. Columbia University – M.S. Enterprise Risk Management (School of Professional Studies)  \n",
    "2. Harvard Extension School – A.L.M. in Management  \n",
    "3. NYU School of Professional Studies – M.S. Integrated Marketing  \n",
    "4. Johns Hopkins Engineering for Professionals – M.S. Cybersecurity  \n",
    "\n",
    "Unless the website clearly meets the criteria above, label the program **non-professional**.  \n",
    "────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "⚠️  **Output format**  \n",
    "Return **exactly one line**: either  \n",
    "``professional``  \n",
    "or  \n",
    "``non-professional``  \n",
    "No additional words, punctuation, or explanations.\n",
    "\n",
    "Links to consult:  \n",
    "• Admissions URL: {admissions_url}  \n",
    "• Program URL: {program_url}\n",
    "\n",
    "Is this program a professional program?\n",
    "\"\"\"\n",
    "\n",
    "    json_file_path = \"/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/DataScience/fields_records/职业项目/职业项目_gemini-2.5-pro_0_-1.json\"\n",
    "    \n",
    "    stats = await fill_invalid_responses(\n",
    "        json_file_path=json_file_path,\n",
    "        prompt_template=prompt_template,\n",
    "        validation_func=is_valid_professional_response,\n",
    "        model_name=\"gemini-2.5-flash\",\n",
    "        max_retries=2\n",
    "    )\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# 运行修复\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# 执行修复\n",
    "stats = asyncio.run(fix_professional_classification())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "职业项目分类统计:\n",
      "总项目数: 350\n",
      "一致认为是professional: 170 (48.6%)\n",
      "一致认为是non-professional: 130 (37.1%)\n",
      "多数票professional: 25 (7.1%)\n",
      "多数票non-professional: 25 (7.1%)\n",
      "票数相等: 0 (0.0%)\n",
      "所有回答均无效: 0 (0.0%)\n",
      "总有效回答数: 1046\n",
      "总无效回答数: 4\n",
      "平均每项目有效回答数: 2.99\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def process_professional_classification(json_file_path, output_csv_path):\n",
    "    \"\"\"\n",
    "    Process professional/non-professional classification from JSON file with majority voting.\n",
    "    \n",
    "    Args:\n",
    "        json_file_path (str): Path to the JSON file containing professional classification data\n",
    "        output_csv_path (str): Path to save the output CSV file\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with classification results and statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    def is_valid_response(response_text):\n",
    "        \"\"\"Check if a response is valid (professional or non-professional)\"\"\"\n",
    "        if not response_text or response_text.strip() == \"\":\n",
    "            return False, \"空白回答\"\n",
    "        \n",
    "        response_clean = response_text.strip().lower()\n",
    "        \n",
    "        # Check for overly long responses (likely explanatory text rather than classification)\n",
    "        if len(response_text) > 100:\n",
    "            return False, \"回答过长\"\n",
    "        \n",
    "        # Check if response is exactly one of the two valid classifications\n",
    "        if response_clean in [\"professional\", \"non-professional\"]:\n",
    "            return True, \"有效回答\"\n",
    "        \n",
    "        return False, \"无效分类\"\n",
    "    \n",
    "    # Load JSON data\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    results = []\n",
    "    stats = {\n",
    "        'total_programs': 0,\n",
    "        'unanimous_professional': 0,\n",
    "        'unanimous_non_professional': 0,\n",
    "        'majority_professional': 0,\n",
    "        'majority_non_professional': 0,\n",
    "        'tied_votes': 0,\n",
    "        'all_invalid': 0,\n",
    "        'total_valid_responses': 0,\n",
    "        'total_invalid_responses': 0\n",
    "    }\n",
    "    \n",
    "    for program in data:\n",
    "        stats['total_programs'] += 1\n",
    "        \n",
    "        # Extract basic info\n",
    "        university = program.get('大学英文名称', '')\n",
    "        degree = program.get('学位', '')\n",
    "        major = program.get('专业英文名称', '')\n",
    "        school = program.get('所属院系', '')\n",
    "        \n",
    "        # Extract responses\n",
    "        llm_responses = program.get('llm_reponses', {})\n",
    "        \n",
    "        # Process each response\n",
    "        response_data = {}\n",
    "        valid_responses = []\n",
    "        \n",
    "        for response_num in range(1, 4):\n",
    "            response_key = f\"response {response_num}\"\n",
    "            response_text = \"\"\n",
    "            \n",
    "            if response_key in llm_responses:\n",
    "                response_text = llm_responses[response_key].get('response_text', '')\n",
    "            \n",
    "            # Validate response\n",
    "            is_valid, status = is_valid_response(response_text)\n",
    "            \n",
    "            # Store response details\n",
    "            response_data[f'response_{response_num}_text'] = response_text\n",
    "            response_data[f'response_{response_num}_status'] = status\n",
    "            response_data[f'response_{response_num}_valid'] = is_valid\n",
    "            \n",
    "            # Add to valid responses if valid\n",
    "            if is_valid:\n",
    "                valid_responses.append(response_text.strip().lower())\n",
    "        \n",
    "        # Count valid and invalid responses\n",
    "        valid_count = len(valid_responses)\n",
    "        invalid_count = 3 - valid_count\n",
    "        stats['total_valid_responses'] += valid_count\n",
    "        stats['total_invalid_responses'] += invalid_count\n",
    "        \n",
    "        # Determine final classification\n",
    "        if valid_count == 0:\n",
    "            final_classification = \"需要额外确认\"\n",
    "            voting_status = \"所有回答均无效\"\n",
    "            stats['all_invalid'] += 1\n",
    "        else:\n",
    "            # Count votes\n",
    "            vote_counts = Counter(valid_responses)\n",
    "            professional_votes = vote_counts.get('professional', 0)\n",
    "            non_professional_votes = vote_counts.get('non-professional', 0)\n",
    "            \n",
    "            if professional_votes == non_professional_votes:\n",
    "                # Tie\n",
    "                final_classification = \"需要额外确认\"\n",
    "                voting_status = f\"票数相等({professional_votes}票professional vs {non_professional_votes}票non-professional)\"\n",
    "                stats['tied_votes'] += 1\n",
    "            elif professional_votes > non_professional_votes:\n",
    "                final_classification = 'professional'\n",
    "                if valid_count == professional_votes:  # All valid votes are professional\n",
    "                    voting_status = f\"一致投票({valid_count}/3有效)\"\n",
    "                    stats['unanimous_professional'] += 1\n",
    "                else:\n",
    "                    voting_status = f\"多数票({professional_votes}票professional vs {non_professional_votes}票non-professional)\"\n",
    "                    stats['majority_professional'] += 1\n",
    "            else:  # non_professional_votes > professional_votes\n",
    "                final_classification = 'non-professional'\n",
    "                if valid_count == non_professional_votes:  # All valid votes are non-professional\n",
    "                    voting_status = f\"一致投票({valid_count}/3有效)\"\n",
    "                    stats['unanimous_non_professional'] += 1\n",
    "                else:\n",
    "                    voting_status = f\"多数票({non_professional_votes}票non-professional vs {professional_votes}票professional)\"\n",
    "                    stats['majority_non_professional'] += 1\n",
    "        \n",
    "        # Create result record\n",
    "        result_record = {\n",
    "            '大学英文名称': university,\n",
    "            '学位': degree,\n",
    "            '专业英文名称': major,\n",
    "            '所属院系': school,\n",
    "            '职业项目': final_classification,\n",
    "            '投票状态': voting_status\n",
    "        }\n",
    "        \n",
    "        # Add response details\n",
    "        result_record.update(response_data)\n",
    "        \n",
    "        results.append(result_record)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"职业项目分类统计:\")\n",
    "    print(f\"总项目数: {stats['total_programs']}\")\n",
    "    print(f\"一致认为是professional: {stats['unanimous_professional']} ({stats['unanimous_professional']/stats['total_programs']*100:.1f}%)\")\n",
    "    print(f\"一致认为是non-professional: {stats['unanimous_non_professional']} ({stats['unanimous_non_professional']/stats['total_programs']*100:.1f}%)\")\n",
    "    print(f\"多数票professional: {stats['majority_professional']} ({stats['majority_professional']/stats['total_programs']*100:.1f}%)\")\n",
    "    print(f\"多数票non-professional: {stats['majority_non_professional']} ({stats['majority_non_professional']/stats['total_programs']*100:.1f}%)\")\n",
    "    print(f\"票数相等: {stats['tied_votes']} ({stats['tied_votes']/stats['total_programs']*100:.1f}%)\")\n",
    "    print(f\"所有回答均无效: {stats['all_invalid']} ({stats['all_invalid']/stats['total_programs']*100:.1f}%)\")\n",
    "    print(f\"总有效回答数: {stats['total_valid_responses']}\")\n",
    "    print(f\"总无效回答数: {stats['total_invalid_responses']}\")\n",
    "    \n",
    "    if stats['total_programs'] > 0:\n",
    "        print(f\"平均每项目有效回答数: {stats['total_valid_responses']/stats['total_programs']:.2f}\")\n",
    "    \n",
    "    return df, stats\n",
    "\n",
    "# Usage:\n",
    "df, stats = process_professional_classification(\n",
    "    '/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/DataScience/fields_records/职业项目/职业项目_gemini-2.5-pro_0_-1_fixed.json',\n",
    "    '/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/DataScience/fields_records/职业项目.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
