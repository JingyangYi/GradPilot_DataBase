{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 9)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "sys.path.append('/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/DataScience')\n",
    "import asyncio\n",
    "from call_api import call_gemini, async_call_gemini\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "field_name = \"更多项目信息\"\n",
    "field_path = f\"/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/DataScience/fields_csv/{field_name}.csv\"\n",
    "field_df = pd.read_csv(field_path)\n",
    "\n",
    "field_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an assistant whose only task is to extract and concisely summarize the **key academic and career-oriented selling points** of the graduate program below.\n",
    "\n",
    "────────────────────────────────────────────────────────\n",
    "What to include  \n",
    "• Ph.D. programs → main research areas, faculty strengths, lab resources, interdisciplinary links.  \n",
    "• Academic Master’s → signature courses, research or thesis options, unique concentrations.  \n",
    "• Professional Master’s → industry partnerships, internship / practicum opportunities, career services, ROI claims.  \n",
    "Goal: deliver **3-5 crisp bullet points** that highlight the program’s distinct features or advantages.\n",
    "\n",
    "────────────────────────────────────────────────────────\n",
    "How to gather information  \n",
    "\n",
    "1. **Primary *.edu* sources only**  \n",
    "   • Follow the Program URLs provided.  \n",
    "   • You may open any additional pages under the same university’s *.edu* domain (e.g., “About the Program”, “Research”, “Careers”, “Why Choose Us”).  \n",
    "   ⛔  Ignore non-*.edu* sites, blogs, rankings, or promo videos without text.\n",
    "\n",
    "2. **Optional Google search**  \n",
    "   Single query:  \n",
    "   \"{university} {degree} {program} overview research career site:.edu\"  \n",
    "   Examine only *.edu* results.\n",
    "\n",
    "3. **Summarize**  \n",
    "   • Extract concrete selling points (avoid generic statements like “world-class faculty”).  \n",
    "   • Each bullet ≤ 25 words, start with a strong noun phrase; skip long subjects like “The program offers…”.  \n",
    "   • Provide at least **3** and at most **5** bullets.  \n",
    "   • If no reliable *.edu* info is found, output **Not found**.  \n",
    "   • Never invent.\n",
    "\n",
    "────────────────────────────────────────────────────────\n",
    "⚠️  Output format (exactly one line per bullet; no extra text before or after)\n",
    "\n",
    "Example of valid output:  \n",
    "• Three research tracks: AI systems, probabilistic ML, and human-AI interaction  \n",
    "• 12-month capstone + industry practicum with Fortune-500 partners  \n",
    "• NSF-funded labs and dedicated GPU cluster for Ph.D. students  \n",
    "• STEM-OPT eligible, 95 % job placement within six months  \n",
    "\n",
    "If nothing can be confirmed:  \n",
    "Not found\n",
    "\n",
    "\n",
    "────────────────────────────────────────────────────────\n",
    "• Admissions URL: {admissions_url}  \n",
    "• Program URL:    {program_url}\n",
    "\n",
    "Provide the program snapshot:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "# Async Gemini wrapper\n",
    "from call_api import async_call_gemini\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Concurrency guard – avoid hitting rate-limits\n",
    "# ---------------------------------------------------------------------------\n",
    "semaphore = asyncio.Semaphore(4)            # max concurrent rows\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Per-row worker\n",
    "# ---------------------------------------------------------------------------\n",
    "async def process_row(row, prompt_template, num_vote: int, model_name: str):\n",
    "    \"\"\"\n",
    "    1. Format the prompt for this row\n",
    "    2. Launch `num_vote` Gemini calls in parallel\n",
    "    3. Capture BOTH normal answers *and* every possible error case\n",
    "    4. Return a serialisable record\n",
    "    \"\"\"\n",
    "    async with semaphore:\n",
    "        row    = row.to_dict()\n",
    "        prompt = prompt_template.format(\n",
    "            university     = row[\"大学英文名称\"],\n",
    "            degree         = row[\"学位\"],\n",
    "            program        = row[\"专业英文名称\"],\n",
    "            department     = row[\"所属院系\"],\n",
    "            admissions_url = row[\"招生网址\"],\n",
    "            program_url    = row[\"专业网址\"],\n",
    "        )\n",
    "\n",
    "        record: dict = row.copy()\n",
    "        record[\"llm_reponses\"] = {}\n",
    "\n",
    "        # -------- launch Gemini calls in parallel --------------------\n",
    "        tasks = [\n",
    "            async_call_gemini(\n",
    "                prompt,\n",
    "                model_name=model_name,\n",
    "                use_search=True,\n",
    "                url_context=True\n",
    "            )\n",
    "            for _ in range(num_vote)\n",
    "        ]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "\n",
    "        # -------- post-process each response -------------------------\n",
    "        for i, response in enumerate(responses):\n",
    "            resp_key = f\"response {i+1}\"\n",
    "\n",
    "            # -- 1. Transport / server-side errors (string starting \"Error:\")\n",
    "            if isinstance(response, str) and response.startswith(\"Error:\"):\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": response                       # e.g. \"Error: 429 Rate limit …\"\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 2. Empty / malformed response objects\n",
    "            if not hasattr(response, \"candidates\") or not response.candidates:\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": \"No candidates returned\",\n",
    "                    \"raw_response\": str(response)\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 3. Extract main answer text\n",
    "            try:\n",
    "                text = response.candidates[0].content.parts[0].text\n",
    "            except Exception as e:\n",
    "                record[\"llm_reponses\"][resp_key] = {\n",
    "                    \"error\": f\"Cannot parse text: {e}\",\n",
    "                    \"raw_response\": str(response)\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            # -- 4. Extract additional metadata (best-effort)\n",
    "            try:\n",
    "                url_context = str(response.candidates[0].url_context_metadata)\n",
    "            except Exception:\n",
    "                url_context = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_pages = (\n",
    "                    f\"Search Chunks: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.grounding_chunks}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_pages = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_queries = (\n",
    "                    f\"Search Query: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.web_search_queries}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_queries = \"Not used\"\n",
    "\n",
    "            try:\n",
    "                search_support = (\n",
    "                    f\"Search Supports: \"\n",
    "                    f\"{response.candidates[0].grounding_metadata.groundingSupports}\"\n",
    "                )\n",
    "            except Exception:\n",
    "                search_support = \"Not used\"\n",
    "\n",
    "            # -- 5. Store normal answer + metadata + raw object\n",
    "            record[\"llm_reponses\"][resp_key] = {\n",
    "                \"response_text\": text,\n",
    "                \"url_context\": url_context,\n",
    "                \"search_queries\": search_queries,\n",
    "                \"search_pages\": search_pages,\n",
    "                \"search_support\": search_support,\n",
    "                \"raw_response\": str(response)             # keep for deep-debugging\n",
    "            }\n",
    "\n",
    "        return record\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Batch orchestrator with tqdm progress bar\n",
    "# ---------------------------------------------------------------------------\n",
    "async def request_and_store_async(prompt_template,\n",
    "                                  field_df,\n",
    "                                  num_vote: int,\n",
    "                                  model_name: str,\n",
    "                                  start_from: int = 0,\n",
    "                                  end_at: int = -1):\n",
    "    \"\"\"\n",
    "    Runs `process_row` over the dataframe slice asynchronously,\n",
    "    shows a live tqdm bar, and dumps the results to JSON.\n",
    "    \"\"\"\n",
    "    df = field_df.copy()[start_from:end_at]\n",
    "\n",
    "    # Spawn tasks for every row in the slice\n",
    "    tasks = [\n",
    "        process_row(row, prompt_template, num_vote, model_name)\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # tqdm_asyncio.gather gives us progress updates as tasks complete\n",
    "    response_records = await tqdm_asyncio.gather(*tasks)\n",
    "\n",
    "    # Persist to disk ------------------------------------------------\n",
    "    output_dir = f\"../fields_records/{field_name}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = f\"{output_dir}/{field_name}_{model_name}_{start_from}_{end_at}.json\"\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(response_records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return response_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [23:58<00:00,  4.11s/it]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Only needed in Jupyter\n",
    "\n",
    "num_vote = 3\n",
    "start_from = 0\n",
    "end_at = -1\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "response_records = asyncio.run(\n",
    "    request_and_store_async(prompt_template, field_df, num_vote, model_name, start_from=start_from, end_at=end_at)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据提取完成！\n",
      "总共处理了 350 条记录\n",
      "结果已保存到: /Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/DataScience/fields_records/更多项目信息/更多项目信息_提取结果.csv\n",
      "\n",
      "数据统计:\n",
      "- 有更多项目信息的记录数: 350\n",
      "- 缺失更多项目信息的记录数: 0\n",
      "\n",
      "数据预览:\n",
      "                大学英文名称  学位                       专业英文名称  \\\n",
      "0   Harvard University  MS            Data Science SEAS   \n",
      "1   Harvard University  MS                 Data Science   \n",
      "2  Stanford University  MS                 Data Science   \n",
      "3  Stanford University  MS                 Data Science   \n",
      "4      Yale University  MS  Statistics and Data Science   \n",
      "\n",
      "                       所属院系  \\\n",
      "0           约翰·保尔森工程与应用科学学院   \n",
      "1  Harvard Extension School   \n",
      "2                      工程学院   \n",
      "3                    人文科学学院   \n",
      "4                 艺术与科学研究生院   \n",
      "\n",
      "                                            所属院系（英文）  \\\n",
      "0  Harvard John A. Paulson School of Engineering ...   \n",
      "1                           Harvard Extension School   \n",
      "2                              School of Engineering   \n",
      "3                  School of Humanities and Sciences   \n",
      "4               Graduate School of Arts and Sciences   \n",
      "\n",
      "                                                招生网址  \\\n",
      "0  https://seas.harvard.edu/masters-data-science/...   \n",
      "1  https://extension.harvard.edu/registration-adm...   \n",
      "2  https://icme.stanford.edu/academics-admission/...   \n",
      "3  https://statistics.stanford.edu/msadmissionsms...   \n",
      "4  https://gsas.yale.edu/programs-of-study/statis...   \n",
      "\n",
      "                                                专业网址  \\\n",
      "0      https://seas.harvard.edu/masters-data-science   \n",
      "1  https://extension.harvard.edu/academics/progra...   \n",
      "2  https://icme.stanford.edu/academics-admission/...   \n",
      "3  https://statistics.stanford.edu/graduate-progr...   \n",
      "4  https://statistics.yale.edu/academics/terminal...   \n",
      "\n",
      "                             所属院系网址  \\\n",
      "0          https://seas.harvard.edu   \n",
      "1     https://extension.harvard.edu   \n",
      "2  https://engineering.stanford.edu   \n",
      "3      https://humsci.stanford.edu/   \n",
      "4             https://gsas.yale.edu   \n",
      "\n",
      "                                              更多项目信息  \n",
      "0  • Interdisciplinary foundation: Jointly led by...  \n",
      "1  • Industry-partnered capstone with real-world ...  \n",
      "2  • Four distinct MS tracks: Data Science, Imagi...  \n",
      "3  • Focused 45-unit curriculum building strong m...  \n",
      "4  • Comprehensive Curriculum: Broad training in ...  \n",
      "\n",
      "CSV文件包含以下列:\n",
      "1. 大学英文名称\n",
      "2. 学位\n",
      "3. 专业英文名称\n",
      "4. 所属院系\n",
      "5. 所属院系（英文）\n",
      "6. 招生网址\n",
      "7. 专业网址\n",
      "8. 所属院系网址\n",
      "9. 更多项目信息\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def extract_program_info_from_json(json_file_path):\n",
    "    \"\"\"\n",
    "    从JSON文件中提取项目信息，选择response 1作为\"更多项目信息\"的值\n",
    "    \n",
    "    Args:\n",
    "        json_file_path: JSON文件路径\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: 处理后的数据\n",
    "    \"\"\"\n",
    "    \n",
    "    # 读取JSON文件\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for record in data:\n",
    "        # 提取基本信息\n",
    "        basic_info = {\n",
    "            '大学英文名称': record.get('大学英文名称', '').strip(),\n",
    "            '学位': record.get('学位', ''),\n",
    "            '专业英文名称': record.get('专业英文名称', ''),\n",
    "            '所属院系': record.get('所属院系', ''),\n",
    "            '所属院系（英文）': record.get('所属院系（英文）', ''),\n",
    "            '招生网址': record.get('招生网址', ''),\n",
    "            '专业网址': record.get('专业网址', ''),\n",
    "            '所属院系网址': record.get('所属院系网址', ''),\n",
    "        }\n",
    "        \n",
    "        # 提取response 1的内容作为\"更多项目信息\"\n",
    "        更多项目信息 = ''\n",
    "        try:\n",
    "            # 注意这里是 llm_reponses，不是 llm_responses\n",
    "            if ('llm_reponses' in record and \n",
    "                'response 1' in record['llm_reponses'] and \n",
    "                'response_text' in record['llm_reponses']['response 1']):\n",
    "                更多项目信息 = record['llm_reponses']['response 1']['response_text']\n",
    "        except (KeyError, TypeError) as e:\n",
    "            print(f\"处理记录时出错: {record.get('大学英文名称', 'Unknown')} - {e}\")\n",
    "            更多项目信息 = ''\n",
    "        # 将所有信息合并\n",
    "        result = basic_info.copy()\n",
    "        result['更多项目信息'] = 更多项目信息\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    # 转换为DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # 生成输出文件路径（在同一文件夹中）\n",
    "    output_dir = os.path.dirname(json_file_path)\n",
    "    output_filename = '更多项目信息_提取结果.csv'\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    \n",
    "    # 保存为CSV文件\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"数据提取完成！\")\n",
    "    print(f\"总共处理了 {len(results)} 条记录\")\n",
    "    print(f\"结果已保存到: {output_path}\")\n",
    "    \n",
    "    # 显示一些统计信息\n",
    "    print(f\"\\n数据统计:\")\n",
    "    print(f\"- 有更多项目信息的记录数: {df['更多项目信息'].notna().sum()}\")\n",
    "    print(f\"- 缺失更多项目信息的记录数: {df['更多项目信息'].isna().sum()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "json_file_path = \"/Users/yijingyang/Library/CloudStorage/OneDrive-个人/GradPilot/ProgramDB/DataScience/fields_records/更多项目信息/更多项目信息_gemini-2.5-flash_0_-1.json\"\n",
    "\n",
    "df = extract_program_info_from_json(json_file_path)\n",
    "\n",
    "# 显示前几行数据预览\n",
    "print(\"\\n数据预览:\")\n",
    "print(df.head())\n",
    "\n",
    "# 显示列信息\n",
    "print(f\"\\nCSV文件包含以下列:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
