{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– è¯»å–ä¸»æ•°æ®é›†...\n",
      "ä¸»æ•°æ®é›†åŒ…å« 351 ä¸ªé¡¹ç›®\n",
      "\n",
      "ğŸ”„ å¼€å§‹æ·»åŠ å­—æ®µæ•°æ®...\n",
      "============================================================\n",
      "\n",
      "ğŸ“ å¤„ç†æ–‡ä»¶å¤¹: æ›´å¤šé¡¹ç›®ä¿¡æ¯\n",
      "ğŸ“„ ç›®æ ‡æ–‡ä»¶: æ›´å¤šé¡¹ç›®ä¿¡æ¯_æå–ç»“æœ.csv\n",
      "ğŸ¯ æ·»åŠ å­—æ®µ: ['æ›´å¤šé¡¹ç›®ä¿¡æ¯']\n",
      "   ğŸ“– è¯»å–æ–‡ä»¶...\n",
      "   ğŸ“Š æ‰¾åˆ° 350 æ¡è®°å½•\n",
      "   âš ï¸  è­¦å‘Š: è¡Œæ•°ä¸åŒ¹é…! ä¸»æ•°æ®é›†: 351, å­—æ®µæ–‡ä»¶: 350\n",
      "   ğŸ“ ä½¿ç”¨æœ€å°é•¿åº¦: 350\n",
      "   â• æ·»åŠ å­—æ®µ: ['æ›´å¤šé¡¹ç›®ä¿¡æ¯']\n",
      "     ğŸ“ æ·»åŠ : æ›´å¤šé¡¹ç›®ä¿¡æ¯\n",
      "   âœ… æˆåŠŸæ·»åŠ  1 ä¸ªå­—æ®µ\n",
      "   ğŸ“Š éç©ºå€¼ç»Ÿè®¡: æ›´å¤šé¡¹ç›®ä¿¡æ¯: 343/351\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“ å¤„ç†æ–‡ä»¶å¤¹: è¯¾ç¨‹ç½‘å€\n",
      "ğŸ“„ ç›®æ ‡æ–‡ä»¶: è¯¾ç¨‹ç½‘å€_è§„åˆ™å¤„ç†ç»“æœ.csv\n",
      "ğŸ¯ æ·»åŠ å­—æ®µ: ['è¯¾ç¨‹ç½‘å€']\n",
      "   ğŸ“– è¯»å–æ–‡ä»¶...\n",
      "   ğŸ“Š æ‰¾åˆ° 350 æ¡è®°å½•\n",
      "   âš ï¸  è­¦å‘Š: è¡Œæ•°ä¸åŒ¹é…! ä¸»æ•°æ®é›†: 351, å­—æ®µæ–‡ä»¶: 350\n",
      "   ğŸ“ ä½¿ç”¨æœ€å°é•¿åº¦: 350\n",
      "   â• æ·»åŠ å­—æ®µ: ['è¯¾ç¨‹ç½‘å€']\n",
      "     ğŸ“ æ·»åŠ : è¯¾ç¨‹ç½‘å€\n",
      "   âœ… æˆåŠŸæ·»åŠ  1 ä¸ªå­—æ®µ\n",
      "   ğŸ“Š éç©ºå€¼ç»Ÿè®¡: è¯¾ç¨‹ç½‘å€: 160/351\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“ å¤„ç†æ–‡ä»¶å¤¹: é¢è¯•\n",
      "ğŸ“„ ç›®æ ‡æ–‡ä»¶: é¢è¯•éœ€æ±‚_å¤„ç†ç»“æœ.csv\n",
      "ğŸ¯ æ·»åŠ å­—æ®µ: ['é¢è¯•newp']\n",
      "   ğŸ“– è¯»å–æ–‡ä»¶...\n",
      "   ğŸ“Š æ‰¾åˆ° 350 æ¡è®°å½•\n",
      "   âš ï¸  è­¦å‘Š: è¡Œæ•°ä¸åŒ¹é…! ä¸»æ•°æ®é›†: 351, å­—æ®µæ–‡ä»¶: 350\n",
      "   ğŸ“ ä½¿ç”¨æœ€å°é•¿åº¦: 350\n",
      "   â• æ·»åŠ å­—æ®µ: ['é¢è¯•newp']\n",
      "     ğŸ“ æ·»åŠ : é¢è¯•newp\n",
      "   âœ… æˆåŠŸæ·»åŠ  1 ä¸ªå­—æ®µ\n",
      "   ğŸ“Š éç©ºå€¼ç»Ÿè®¡: é¢è¯•newp: 298/351\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“ å¤„ç†æ–‡ä»¶å¤¹: ç”³è¯·è´¹å‡å…\n",
      "ğŸ“„ ç›®æ ‡æ–‡ä»¶: final_ç”³è¯·è´¹å‡å…_gemini-2.5-flash_median_accuracy_processed.csv\n",
      "ğŸ¯ æ·»åŠ å­—æ®µ: ['ç”³è¯·è´¹å‡å…']\n",
      "   ğŸ“– è¯»å–æ–‡ä»¶...\n",
      "   ğŸ“Š æ‰¾åˆ° 350 æ¡è®°å½•\n",
      "   âš ï¸  è­¦å‘Š: è¡Œæ•°ä¸åŒ¹é…! ä¸»æ•°æ®é›†: 351, å­—æ®µæ–‡ä»¶: 350\n",
      "   ğŸ“ ä½¿ç”¨æœ€å°é•¿åº¦: 350\n",
      "   â• æ·»åŠ å­—æ®µ: ['ç”³è¯·è´¹å‡å…']\n",
      "     ğŸ“ æ·»åŠ : ç”³è¯·è´¹å‡å…\n",
      "   âœ… æˆåŠŸæ·»åŠ  1 ä¸ªå­—æ®µ\n",
      "   ğŸ“Š éç©ºå€¼ç»Ÿè®¡: ç”³è¯·è´¹å‡å…: 313/351\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“ å¤„ç†æ–‡ä»¶å¤¹: æ‰€å±é™¢ç³»ï¼ˆè‹±æ–‡ï¼‰\n",
      "ğŸ“„ ç›®æ ‡æ–‡ä»¶: æ‰€å±é™¢ç³»è‹±æ–‡_å¤„ç†ç»“æœ.csv\n",
      "ğŸ¯ æ·»åŠ å­—æ®µ: ['æ‰€å±é™¢ç³»è‹±æ–‡åç§°', 'æ‰€å±é™¢ç³»ç½‘å€']\n",
      "   ğŸ“– è¯»å–æ–‡ä»¶...\n",
      "   ğŸ“Š æ‰¾åˆ° 350 æ¡è®°å½•\n",
      "   âš ï¸  è­¦å‘Š: è¡Œæ•°ä¸åŒ¹é…! ä¸»æ•°æ®é›†: 351, å­—æ®µæ–‡ä»¶: 350\n",
      "   ğŸ“ ä½¿ç”¨æœ€å°é•¿åº¦: 350\n",
      "   â• æ·»åŠ å­—æ®µ: ['æ‰€å±é™¢ç³»è‹±æ–‡åç§°', 'æ‰€å±é™¢ç³»ç½‘å€']\n",
      "     ğŸ“ æ·»åŠ : æ‰€å±é™¢ç³»è‹±æ–‡åç§°\n",
      "     ğŸ“ æ·»åŠ : æ‰€å±é™¢ç³»ç½‘å€\n",
      "   âœ… æˆåŠŸæ·»åŠ  2 ä¸ªå­—æ®µ\n",
      "   ğŸ“Š éç©ºå€¼ç»Ÿè®¡: æ‰€å±é™¢ç³»è‹±æ–‡åç§°: 347/351, æ‰€å±é™¢ç³»ç½‘å€: 347/351\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“ å¤„ç†æ–‡ä»¶å¤¹: æ¨èä¿¡\n",
      "ğŸ“„ ç›®æ ‡æ–‡ä»¶: final_æ¨èä¿¡_gemini-2.5-flash_0_-1_processed.csv\n",
      "ğŸ¯ æ·»åŠ å­—æ®µ: ['æ¨èä¿¡']\n",
      "   ğŸ“– è¯»å–æ–‡ä»¶...\n",
      "   ğŸ“Š æ‰¾åˆ° 350 æ¡è®°å½•\n",
      "   âš ï¸  è­¦å‘Š: è¡Œæ•°ä¸åŒ¹é…! ä¸»æ•°æ®é›†: 351, å­—æ®µæ–‡ä»¶: 350\n",
      "   ğŸ“ ä½¿ç”¨æœ€å°é•¿åº¦: 350\n",
      "   â• æ·»åŠ å­—æ®µ: ['æ¨èä¿¡']\n",
      "     ğŸ“ æ·»åŠ : æ¨èä¿¡\n",
      "   âœ… æˆåŠŸæ·»åŠ  1 ä¸ªå­—æ®µ\n",
      "   ğŸ“Š éç©ºå€¼ç»Ÿè®¡: æ¨èä¿¡: 349/351\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“ å¤„ç†æ–‡ä»¶å¤¹: æ‰˜ç¦é€åˆ†ETS code\n",
      "ğŸ“„ ç›®æ ‡æ–‡ä»¶: æ‰˜ç¦é€åˆ†ETS code_gemini-2.5-flash_0_-1_processed.csv\n",
      "ğŸ¯ æ·»åŠ å­—æ®µ: ['æ‰˜ç¦é€åˆ†ETS code']\n",
      "   ğŸ“– è¯»å–æ–‡ä»¶...\n",
      "   ğŸ“Š æ‰¾åˆ° 350 æ¡è®°å½•\n",
      "   âš ï¸  è­¦å‘Š: è¡Œæ•°ä¸åŒ¹é…! ä¸»æ•°æ®é›†: 351, å­—æ®µæ–‡ä»¶: 350\n",
      "   ğŸ“ ä½¿ç”¨æœ€å°é•¿åº¦: 350\n",
      "   â• æ·»åŠ å­—æ®µ: ['æ‰˜ç¦é€åˆ†ETS code']\n",
      "     ğŸ“ æ·»åŠ : æ‰˜ç¦é€åˆ†ETS code\n",
      "   âœ… æˆåŠŸæ·»åŠ  1 ä¸ªå­—æ®µ\n",
      "   ğŸ“Š éç©ºå€¼ç»Ÿè®¡: æ‰˜ç¦é€åˆ†ETS code: 350/351\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“ å¤„ç†æ–‡ä»¶å¤¹: é¡¹ç›®æ ‡ç­¾\n",
      "ğŸ“„ ç›®æ ‡æ–‡ä»¶: é¡¹ç›®æ ‡ç­¾.csv\n",
      "ğŸ¯ æ·»åŠ å­—æ®µ: ['é¡¹ç›®æ ‡ç­¾ï¼ˆè‹±æ–‡ï¼‰', 'é¡¹ç›®æ ‡ç­¾ï¼ˆä¸­æ–‡ï¼‰']\n",
      "   ğŸ“– è¯»å–æ–‡ä»¶...\n",
      "   ğŸ“Š æ‰¾åˆ° 350 æ¡è®°å½•\n",
      "   âš ï¸  è­¦å‘Š: è¡Œæ•°ä¸åŒ¹é…! ä¸»æ•°æ®é›†: 351, å­—æ®µæ–‡ä»¶: 350\n",
      "   ğŸ“ ä½¿ç”¨æœ€å°é•¿åº¦: 350\n",
      "   â• æ·»åŠ å­—æ®µ: ['é¡¹ç›®æ ‡ç­¾ï¼ˆè‹±æ–‡ï¼‰', 'é¡¹ç›®æ ‡ç­¾ï¼ˆä¸­æ–‡ï¼‰']\n",
      "     ğŸ“ æ·»åŠ : é¡¹ç›®æ ‡ç­¾ï¼ˆè‹±æ–‡ï¼‰\n",
      "     ğŸ“ æ·»åŠ : é¡¹ç›®æ ‡ç­¾ï¼ˆä¸­æ–‡ï¼‰\n",
      "   âœ… æˆåŠŸæ·»åŠ  2 ä¸ªå­—æ®µ\n",
      "   ğŸ“Š éç©ºå€¼ç»Ÿè®¡: é¡¹ç›®æ ‡ç­¾ï¼ˆè‹±æ–‡ï¼‰: 350/351, é¡¹ç›®æ ‡ç­¾ï¼ˆä¸­æ–‡ï¼‰: 350/351\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“ å¤„ç†æ–‡ä»¶å¤¹: èŒä¸šé¡¹ç›®\n",
      "ğŸ“„ ç›®æ ‡æ–‡ä»¶: èŒä¸šé¡¹ç›®.csv\n",
      "ğŸ¯ æ·»åŠ å­—æ®µ: ['èŒä¸šé¡¹ç›®']\n",
      "   ğŸ“– è¯»å–æ–‡ä»¶...\n",
      "   ğŸ“Š æ‰¾åˆ° 350 æ¡è®°å½•\n",
      "   âš ï¸  è­¦å‘Š: è¡Œæ•°ä¸åŒ¹é…! ä¸»æ•°æ®é›†: 351, å­—æ®µæ–‡ä»¶: 350\n",
      "   ğŸ“ ä½¿ç”¨æœ€å°é•¿åº¦: 350\n",
      "   â• æ·»åŠ å­—æ®µ: ['èŒä¸šé¡¹ç›®']\n",
      "     ğŸ“ æ·»åŠ : èŒä¸šé¡¹ç›®\n",
      "   âœ… æˆåŠŸæ·»åŠ  1 ä¸ªå­—æ®µ\n",
      "   ğŸ“Š éç©ºå€¼ç»Ÿè®¡: èŒä¸šé¡¹ç›®: 350/351\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“ å¤„ç†æ–‡ä»¶å¤¹: Capstoneæˆ–Thesis\n",
      "ğŸ“„ ç›®æ ‡æ–‡ä»¶: Capstoneæˆ–Thesis_ä¿®å¤ç‰ˆ.csv\n",
      "ğŸ¯ æ·»åŠ å­—æ®µ: ['Geminiæœ€ç»ˆæ¯•ä¸šè¦æ±‚']\n",
      "   ğŸ“– è¯»å–æ–‡ä»¶...\n",
      "   ğŸ“Š æ‰¾åˆ° 350 æ¡è®°å½•\n",
      "   âš ï¸  è­¦å‘Š: è¡Œæ•°ä¸åŒ¹é…! ä¸»æ•°æ®é›†: 351, å­—æ®µæ–‡ä»¶: 350\n",
      "   ğŸ“ ä½¿ç”¨æœ€å°é•¿åº¦: 350\n",
      "   â• æ·»åŠ å­—æ®µ: ['Geminiæœ€ç»ˆæ¯•ä¸šè¦æ±‚']\n",
      "     ğŸ“ æ·»åŠ : Geminiæœ€ç»ˆæ¯•ä¸šè¦æ±‚\n",
      "   âœ… æˆåŠŸæ·»åŠ  1 ä¸ªå­—æ®µ\n",
      "   ğŸ“Š éç©ºå€¼ç»Ÿè®¡: Geminiæœ€ç»ˆæ¯•ä¸šè¦æ±‚: 350/351\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ’¾ ä¿å­˜æ•´åˆç»“æœ...\n",
      "âœ… æ–‡ä»¶å·²ä¿å­˜è‡³: /Users/yijingyang/Library/CloudStorage/OneDrive-ä¸ªäºº/GradPilot/ProgramDB/DataScience/æ±‡æ€»/ç¾ç ”-æ•°æ®ç§‘å­¦.csv\n",
      "\n",
      "ğŸ“Š æ•´åˆå®Œæˆç»Ÿè®¡:\n",
      "============================================================\n",
      "æ€»å­—æ®µç»„æ•°: 10\n",
      "æˆåŠŸæ·»åŠ : 10\n",
      "æ·»åŠ å¤±è´¥: 0\n",
      "æœ€ç»ˆæ•°æ®é›†å¤§å°: 351 è¡Œ Ã— 34 åˆ—\n",
      "\n",
      "ğŸ“‹ è¯¦ç»†å¤„ç†ç»“æœ:\n",
      "âœ… æ›´å¤šé¡¹ç›®ä¿¡æ¯:\n",
      "     è®°å½•æ•°: 350\n",
      "     æ·»åŠ çš„åˆ—: ['æ›´å¤šé¡¹ç›®ä¿¡æ¯']\n",
      "âœ… è¯¾ç¨‹ç½‘å€:\n",
      "     è®°å½•æ•°: 350\n",
      "     æ·»åŠ çš„åˆ—: ['è¯¾ç¨‹ç½‘å€']\n",
      "âœ… é¢è¯•:\n",
      "     è®°å½•æ•°: 350\n",
      "     æ·»åŠ çš„åˆ—: ['é¢è¯•newp']\n",
      "âœ… ç”³è¯·è´¹å‡å…:\n",
      "     è®°å½•æ•°: 350\n",
      "     æ·»åŠ çš„åˆ—: ['ç”³è¯·è´¹å‡å…']\n",
      "âœ… æ‰€å±é™¢ç³»ï¼ˆè‹±æ–‡ï¼‰:\n",
      "     è®°å½•æ•°: 350\n",
      "     æ·»åŠ çš„åˆ—: ['æ‰€å±é™¢ç³»è‹±æ–‡åç§°', 'æ‰€å±é™¢ç³»ç½‘å€']\n",
      "âœ… æ¨èä¿¡:\n",
      "     è®°å½•æ•°: 350\n",
      "     æ·»åŠ çš„åˆ—: ['æ¨èä¿¡']\n",
      "âœ… æ‰˜ç¦é€åˆ†ETS code:\n",
      "     è®°å½•æ•°: 350\n",
      "     æ·»åŠ çš„åˆ—: ['æ‰˜ç¦é€åˆ†ETS code']\n",
      "âœ… é¡¹ç›®æ ‡ç­¾:\n",
      "     è®°å½•æ•°: 350\n",
      "     æ·»åŠ çš„åˆ—: ['é¡¹ç›®æ ‡ç­¾ï¼ˆè‹±æ–‡ï¼‰', 'é¡¹ç›®æ ‡ç­¾ï¼ˆä¸­æ–‡ï¼‰']\n",
      "âœ… èŒä¸šé¡¹ç›®:\n",
      "     è®°å½•æ•°: 350\n",
      "     æ·»åŠ çš„åˆ—: ['èŒä¸šé¡¹ç›®']\n",
      "âœ… Capstoneæˆ–Thesis:\n",
      "     è®°å½•æ•°: 350\n",
      "     æ·»åŠ çš„åˆ—: ['Geminiæœ€ç»ˆæ¯•ä¸šè¦æ±‚']\n",
      "\n",
      "ğŸ” æœ€ç»ˆæ•°æ®è´¨é‡æ£€æŸ¥:\n",
      "æ•°æ®é›†å½¢çŠ¶: (351, 34)\n",
      "åˆ—å: ['å¤§å­¦æ’å', 'å¤§å­¦åç§°', 'å¤§å­¦è‹±æ–‡åç§°', 'æ‰€åœ¨åŸå¸‚', 'ä¸“ä¸šä¸­æ–‡åç§°', 'å­¦ä½', 'ä¸“ä¸šè‹±æ–‡åç§°', 'æ‰€å±é™¢ç³»', 'ä¸“ä¸šé¢†åŸŸ', 'è¯¾ç¨‹é•¿åº¦', 'ç”³è¯·è´¹ï¼ˆç¾å…ƒ)', 'å¼€å­¦æœŸ', 'æˆªæ­¢æ—¥æœŸ', 'GPA', 'æ‰˜ç¦', 'é›…æ€', 'GRE', 'GMAT', 'å­¦æœ¯èƒŒæ™¯', 'ææ–™è¦æ±‚', 'æ‹›ç”Ÿç½‘å€', 'ä¸“ä¸šç½‘å€', 'æ›´å¤šé¡¹ç›®ä¿¡æ¯', 'è¯¾ç¨‹ç½‘å€', 'é¢è¯•newp', 'ç”³è¯·è´¹å‡å…', 'æ‰€å±é™¢ç³»è‹±æ–‡åç§°', 'æ‰€å±é™¢ç³»ç½‘å€', 'æ¨èä¿¡', 'æ‰˜ç¦é€åˆ†ETS code', 'é¡¹ç›®æ ‡ç­¾ï¼ˆè‹±æ–‡ï¼‰', 'é¡¹ç›®æ ‡ç­¾ï¼ˆä¸­æ–‡ï¼‰', 'èŒä¸šé¡¹ç›®', 'Geminiæœ€ç»ˆæ¯•ä¸šè¦æ±‚']\n",
      "\n",
      "ğŸ“ˆ å„å­—æ®µè¦†ç›–ç‡:\n",
      "   æ›´å¤šé¡¹ç›®ä¿¡æ¯: 343/351 (97.7%)\n",
      "   è¯¾ç¨‹ç½‘å€: 160/351 (45.6%)\n",
      "   é¢è¯•newp: 298/351 (84.9%)\n",
      "   ç”³è¯·è´¹å‡å…: 313/351 (89.2%)\n",
      "   æ‰€å±é™¢ç³»è‹±æ–‡åç§°: 347/351 (98.9%)\n",
      "   æ‰€å±é™¢ç³»ç½‘å€: 347/351 (98.9%)\n",
      "   æ¨èä¿¡: 349/351 (99.4%)\n",
      "   æ‰˜ç¦é€åˆ†ETS code: 350/351 (99.7%)\n",
      "   é¡¹ç›®æ ‡ç­¾ï¼ˆè‹±æ–‡ï¼‰: 350/351 (99.7%)\n",
      "   é¡¹ç›®æ ‡ç­¾ï¼ˆä¸­æ–‡ï¼‰: 350/351 (99.7%)\n",
      "   èŒä¸šé¡¹ç›®: 350/351 (99.7%)\n",
      "   Geminiæœ€ç»ˆæ¯•ä¸šè¦æ±‚: 350/351 (99.7%)\n",
      "\n",
      "ğŸ‰ æ•´åˆå®Œæˆ! æœ€ç»ˆæ•°æ®é›†å½¢çŠ¶: (351, 34)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def integrate_fields_to_main_dataset():\n",
    "    \"\"\"\n",
    "    å°†å„ä¸ªå­—æ®µæ–‡ä»¶å¤¹ä¸­çš„CSVæ•°æ®æŒ‰è¡Œç´¢å¼•ç›´æ¥æ·»åŠ åˆ°ä¸»æ•°æ®é›†ä¸­\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: æ•´åˆåçš„æ•°æ®é›†\n",
    "    \"\"\"\n",
    "    \n",
    "    # ä¸»CSVæ–‡ä»¶è·¯å¾„\n",
    "    main_csv_path = \"/Users/yijingyang/Library/CloudStorage/OneDrive-ä¸ªäºº/GradPilot/ProgramDB/DataScience/DataScience_df1.csv\"\n",
    "    \n",
    "    # è¯»å–ä¸»æ•°æ®é›†\n",
    "    print(\"ğŸ“– è¯»å–ä¸»æ•°æ®é›†...\")\n",
    "    main_df = pd.read_csv(main_csv_path, encoding='utf-8-sig')\n",
    "    print(f\"ä¸»æ•°æ®é›†åŒ…å« {len(main_df)} ä¸ªé¡¹ç›®\")\n",
    "    \n",
    "    # å­—æ®µæ˜ å°„é…ç½®ï¼šæ–‡ä»¶å¤¹å -> (CSVæ–‡ä»¶å, è¦æå–çš„å­—æ®µåˆ—è¡¨)\n",
    "    field_configs = {\n",
    "        'æ›´å¤šé¡¹ç›®ä¿¡æ¯': ('æ›´å¤šé¡¹ç›®ä¿¡æ¯_æå–ç»“æœ.csv', ['æ›´å¤šé¡¹ç›®ä¿¡æ¯']),\n",
    "        'è¯¾ç¨‹ç½‘å€': ('è¯¾ç¨‹ç½‘å€_è§„åˆ™å¤„ç†ç»“æœ.csv', ['è¯¾ç¨‹ç½‘å€']),\n",
    "        'é¢è¯•': ('é¢è¯•éœ€æ±‚_å¤„ç†ç»“æœ.csv', ['é¢è¯•newp']),\n",
    "        # 'å…¶ä»–å­—æ®µ': è·³è¿‡\n",
    "        'ç”³è¯·è´¹å‡å…': ('final_ç”³è¯·è´¹å‡å…_gemini-2.5-flash_median_accuracy_processed.csv', ['ç”³è¯·è´¹å‡å…']),\n",
    "        'æ‰€å±é™¢ç³»ï¼ˆè‹±æ–‡ï¼‰': ('æ‰€å±é™¢ç³»è‹±æ–‡_å¤„ç†ç»“æœ.csv', ['æ‰€å±é™¢ç³»è‹±æ–‡åç§°', 'æ‰€å±é™¢ç³»ç½‘å€']),\n",
    "        'æ¨èä¿¡': ('final_æ¨èä¿¡_gemini-2.5-flash_0_-1_processed.csv', ['æ¨èä¿¡']),\n",
    "        'æ‰˜ç¦é€åˆ†ETS code': ('æ‰˜ç¦é€åˆ†ETS code_gemini-2.5-flash_0_-1_processed.csv', ['æ‰˜ç¦é€åˆ†ETS code']),\n",
    "        'é¡¹ç›®æ ‡ç­¾': ('é¡¹ç›®æ ‡ç­¾.csv', ['é¡¹ç›®æ ‡ç­¾ï¼ˆè‹±æ–‡ï¼‰', 'é¡¹ç›®æ ‡ç­¾ï¼ˆä¸­æ–‡ï¼‰']),\n",
    "        'èŒä¸šé¡¹ç›®': ('èŒä¸šé¡¹ç›®.csv', ['èŒä¸šé¡¹ç›®']),\n",
    "        'Capstoneæˆ–Thesis': ('Capstoneæˆ–Thesis_ä¿®å¤ç‰ˆ.csv', ['Geminiæœ€ç»ˆæ¯•ä¸šè¦æ±‚'])\n",
    "    }\n",
    "    \n",
    "    # åŸºç¡€è·¯å¾„\n",
    "    base_path = \"/Users/yijingyang/Library/CloudStorage/OneDrive-ä¸ªäºº/GradPilot/ProgramDB/DataScience/fields_records\"\n",
    "    \n",
    "    # è®°å½•å¤„ç†ç»Ÿè®¡\n",
    "    processing_stats = {\n",
    "        'total_fields': len(field_configs),\n",
    "        'successful_adds': 0,\n",
    "        'failed_adds': 0,\n",
    "        'field_details': {}\n",
    "    }\n",
    "    \n",
    "    print(\"\\nğŸ”„ å¼€å§‹æ·»åŠ å­—æ®µæ•°æ®...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # é€ä¸ªå¤„ç†æ¯ä¸ªå­—æ®µ\n",
    "    for folder_name, (csv_filename, target_columns) in field_configs.items():\n",
    "        print(f\"\\nğŸ“ å¤„ç†æ–‡ä»¶å¤¹: {folder_name}\")\n",
    "        print(f\"ğŸ“„ ç›®æ ‡æ–‡ä»¶: {csv_filename}\")\n",
    "        print(f\"ğŸ¯ æ·»åŠ å­—æ®µ: {target_columns}\")\n",
    "        \n",
    "        # æ„å»ºå®Œæ•´æ–‡ä»¶è·¯å¾„\n",
    "        csv_path = os.path.join(base_path, folder_name, csv_filename)\n",
    "        \n",
    "        field_stats = {\n",
    "            'csv_path': csv_path,\n",
    "            'target_columns': target_columns,\n",
    "            'file_exists': False,\n",
    "            'records_count': 0,\n",
    "            'columns_added': []\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "            if not os.path.exists(csv_path):\n",
    "                print(f\"   âŒ æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}\")\n",
    "                field_stats['error'] = \"æ–‡ä»¶ä¸å­˜åœ¨\"\n",
    "                processing_stats['failed_adds'] += 1\n",
    "                processing_stats['field_details'][folder_name] = field_stats\n",
    "                continue\n",
    "            \n",
    "            field_stats['file_exists'] = True\n",
    "            \n",
    "            # è¯»å–å­—æ®µCSVæ–‡ä»¶\n",
    "            print(f\"   ğŸ“– è¯»å–æ–‡ä»¶...\")\n",
    "            field_df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
    "            field_stats['records_count'] = len(field_df)\n",
    "            print(f\"   ğŸ“Š æ‰¾åˆ° {len(field_df)} æ¡è®°å½•\")\n",
    "            \n",
    "            # æ£€æŸ¥è¡Œæ•°æ˜¯å¦åŒ¹é…\n",
    "            if len(field_df) != len(main_df):\n",
    "                print(f\"   âš ï¸  è­¦å‘Š: è¡Œæ•°ä¸åŒ¹é…! ä¸»æ•°æ®é›†: {len(main_df)}, å­—æ®µæ–‡ä»¶: {len(field_df)}\")\n",
    "                # å¯ä»¥é€‰æ‹©æˆªæ–­æˆ–å¡«å……ï¼Œè¿™é‡Œé€‰æ‹©ä½¿ç”¨è¾ƒçŸ­çš„é•¿åº¦\n",
    "                min_length = min(len(main_df), len(field_df))\n",
    "                print(f\"   ğŸ“ ä½¿ç”¨æœ€å°é•¿åº¦: {min_length}\")\n",
    "            else:\n",
    "                min_length = len(main_df)\n",
    "                print(f\"   âœ… è¡Œæ•°åŒ¹é…: {min_length}\")\n",
    "            \n",
    "            # æ£€æŸ¥æ‰€éœ€åˆ—æ˜¯å¦å­˜åœ¨\n",
    "            available_columns = field_df.columns.tolist()\n",
    "            missing_columns = [col for col in target_columns if col not in available_columns]\n",
    "            \n",
    "            if missing_columns:\n",
    "                print(f\"   âš ï¸  ç¼ºå¤±å­—æ®µ: {missing_columns}\")\n",
    "                print(f\"   ğŸ“‹ å¯ç”¨å­—æ®µ: {available_columns}\")\n",
    "                # åªä½¿ç”¨å­˜åœ¨çš„å­—æ®µ\n",
    "                existing_columns = [col for col in target_columns if col in available_columns]\n",
    "                if not existing_columns:\n",
    "                    print(f\"   âŒ æ²¡æœ‰å¯ç”¨çš„ç›®æ ‡å­—æ®µ\")\n",
    "                    field_stats['error'] = \"æ²¡æœ‰å¯ç”¨çš„ç›®æ ‡å­—æ®µ\"\n",
    "                    processing_stats['failed_adds'] += 1\n",
    "                    processing_stats['field_details'][folder_name] = field_stats\n",
    "                    continue\n",
    "                target_columns = existing_columns\n",
    "            \n",
    "            # ç›´æ¥æ·»åŠ å­—æ®µåˆ°ä¸»æ•°æ®é›†\n",
    "            print(f\"   â• æ·»åŠ å­—æ®µ: {target_columns}\")\n",
    "            added_columns = []\n",
    "            \n",
    "            for column in target_columns:\n",
    "                if column in field_df.columns:\n",
    "                    # ç¡®ä¿ä¸ä¼šè¦†ç›–å·²å­˜åœ¨çš„åŒååˆ—\n",
    "                    new_column_name = column\n",
    "                    counter = 1\n",
    "                    while new_column_name in main_df.columns:\n",
    "                        new_column_name = f\"{column}_{counter}\"\n",
    "                        counter += 1\n",
    "                    \n",
    "                    # æ·»åŠ åˆ—æ•°æ®ï¼ˆæˆªæ–­åˆ°æœ€å°é•¿åº¦ï¼‰\n",
    "                    main_df[new_column_name] = field_df[column].iloc[:min_length].reset_index(drop=True)\n",
    "                    added_columns.append(new_column_name)\n",
    "                    \n",
    "                    if new_column_name != column:\n",
    "                        print(f\"     ğŸ“ {column} â†’ {new_column_name} (é‡å‘½åé¿å…å†²çª)\")\n",
    "                    else:\n",
    "                        print(f\"     ğŸ“ æ·»åŠ : {column}\")\n",
    "            \n",
    "            field_stats['columns_added'] = added_columns\n",
    "            \n",
    "            # ç»Ÿè®¡éç©ºå€¼\n",
    "            non_null_stats = []\n",
    "            for col in added_columns:\n",
    "                non_null_count = main_df[col].notna().sum()\n",
    "                non_null_stats.append(f\"{col}: {non_null_count}/{len(main_df)}\")\n",
    "            \n",
    "            print(f\"   âœ… æˆåŠŸæ·»åŠ  {len(added_columns)} ä¸ªå­—æ®µ\")\n",
    "            print(f\"   ğŸ“Š éç©ºå€¼ç»Ÿè®¡: {', '.join(non_null_stats)}\")\n",
    "            \n",
    "            processing_stats['successful_adds'] += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ å¤„ç†å¤±è´¥: {str(e)}\")\n",
    "            field_stats['error'] = str(e)\n",
    "            processing_stats['failed_adds'] += 1\n",
    "        \n",
    "        processing_stats['field_details'][folder_name] = field_stats\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    # ä¿å­˜ç»“æœ\n",
    "    output_dir = \"/Users/yijingyang/Library/CloudStorage/OneDrive-ä¸ªäºº/GradPilot/ProgramDB/DataScience/æ±‡æ€»\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, \"ç¾ç ”-æ•°æ®ç§‘å­¦.csv\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ ä¿å­˜æ•´åˆç»“æœ...\")\n",
    "    main_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"âœ… æ–‡ä»¶å·²ä¿å­˜è‡³: {output_path}\")\n",
    "    \n",
    "    # è¾“å‡ºå¤„ç†ç»Ÿè®¡\n",
    "    print(f\"\\nğŸ“Š æ•´åˆå®Œæˆç»Ÿè®¡:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"æ€»å­—æ®µç»„æ•°: {processing_stats['total_fields']}\")\n",
    "    print(f\"æˆåŠŸæ·»åŠ : {processing_stats['successful_adds']}\")\n",
    "    print(f\"æ·»åŠ å¤±è´¥: {processing_stats['failed_adds']}\")\n",
    "    print(f\"æœ€ç»ˆæ•°æ®é›†å¤§å°: {main_df.shape[0]} è¡Œ Ã— {main_df.shape[1]} åˆ—\")\n",
    "    \n",
    "    # è¯¦ç»†ç»Ÿè®¡\n",
    "    print(f\"\\nğŸ“‹ è¯¦ç»†å¤„ç†ç»“æœ:\")\n",
    "    for folder_name, stats in processing_stats['field_details'].items():\n",
    "        status = \"âœ…\" if 'error' not in stats else \"âŒ\"\n",
    "        print(f\"{status} {folder_name}:\")\n",
    "        if 'error' in stats:\n",
    "            print(f\"     é”™è¯¯: {stats['error']}\")\n",
    "        else:\n",
    "            print(f\"     è®°å½•æ•°: {stats['records_count']}\")\n",
    "            print(f\"     æ·»åŠ çš„åˆ—: {stats['columns_added']}\")\n",
    "    \n",
    "    # æ£€æŸ¥æœ€ç»ˆæ•°æ®è´¨é‡\n",
    "    print(f\"\\nğŸ” æœ€ç»ˆæ•°æ®è´¨é‡æ£€æŸ¥:\")\n",
    "    print(f\"æ•°æ®é›†å½¢çŠ¶: {main_df.shape}\")\n",
    "    print(f\"åˆ—å: {list(main_df.columns)}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºæ¯åˆ—çš„éç©ºå€¼ç»Ÿè®¡\n",
    "    print(f\"\\nğŸ“ˆ å„å­—æ®µè¦†ç›–ç‡:\")\n",
    "    total_records = len(main_df)\n",
    "    \n",
    "    # åªæ˜¾ç¤ºæ–°æ·»åŠ çš„å­—æ®µçš„ç»Ÿè®¡\n",
    "    original_columns = ['å¤§å­¦æ’å', 'å¤§å­¦åç§°', 'å¤§å­¦è‹±æ–‡åç§°', 'æ‰€åœ¨åŸå¸‚', 'ä¸“ä¸šä¸­æ–‡åç§°', 'å­¦ä½', \n",
    "                       'ä¸“ä¸šè‹±æ–‡åç§°', 'æ‰€å±é™¢ç³»', 'ä¸“ä¸šé¢†åŸŸ', 'è¯¾ç¨‹é•¿åº¦', 'ç”³è¯·è´¹ï¼ˆç¾å…ƒ)', 'å¼€å­¦æœŸ', \n",
    "                       'æˆªæ­¢æ—¥æœŸ', 'GPA', 'æ‰˜ç¦', 'é›…æ€', 'GRE', 'GMAT', 'å­¦æœ¯èƒŒæ™¯', 'ææ–™è¦æ±‚', \n",
    "                       'æ‹›ç”Ÿç½‘å€', 'ä¸“ä¸šç½‘å€']\n",
    "    \n",
    "    new_columns = [col for col in main_df.columns if col not in original_columns]\n",
    "    \n",
    "    for column in new_columns:\n",
    "        non_null_count = main_df[column].notna().sum()\n",
    "        coverage = (non_null_count / total_records) * 100\n",
    "        print(f\"   {column}: {non_null_count}/{total_records} ({coverage:.1f}%)\")\n",
    "    \n",
    "    return main_df, processing_stats\n",
    "\n",
    "# è¿è¡Œæ•´åˆå‡½æ•°\n",
    "if __name__ == \"__main__\":\n",
    "    final_df, stats = integrate_fields_to_main_dataset()\n",
    "    print(f\"\\nğŸ‰ æ•´åˆå®Œæˆ! æœ€ç»ˆæ•°æ®é›†å½¢çŠ¶: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
